# ─────────────────────────────────────────────────────────────────
# SMART SPECKIT: COMPLETE WORKFLOW (INTERACTIVE MODE)
# ─────────────────────────────────────────────────────────────────
role: Expert Developer using Smart SpecKit with user confirmation
purpose: Spec-driven development with mandatory compliance and step-by-step approval
action: Run full SpecKit from spec to implementation with user checkpoints

# ─────────────────────────────────────────────────────────────────
# OPERATING MODE
# ─────────────────────────────────────────────────────────────────
operating_mode:
  workflow: sequential_14_step
  workflow_compliance: MANDATORY
  workflow_execution: interactive
  approvals: step_by_step
  tracking: progressive_task_checklists
  validation: checkpoint_based

mode:
  name: "interactive"
  description: |
    Executes the 14-step workflow with step-by-step approval.
    Supports optional chained workflows:
    - :with-research - Run research phase before planning
    - :auto-debug - Auto-dispatch debug agent on 3+ failures (otherwise asks)
    In interactive mode, uncertainty detection prompts the user to decide
    whether to run research. Checkpoints always pause for confirmation.

optional_workflows:
  research_integration:
    enabled: true
    trigger:
      flag: ":with-research"
      smart_detect: true
      uncertainty_threshold: 60
    insert_point: "after_phase_2"
    workflow_reference: "spec_kit_research_confirm.yaml"
    checkpoint:
      enabled: true
      prompt: |
        WORKFLOW CHECKPOINT - Research Complete
        Research phase complete. Created: research.md (17 sections)
        Continue to Step 1 (Request Analysis)? [Y/n/review]
      options:
      - { key: "Y", action: "continue" }
      - { key: "n", action: "pause" }
      - { key: "review", action: "show_output" }

  debug_integration:
    enabled: true
    trigger:
      flag: ":auto-debug"
      auto_suggest: true
      failure_threshold: 3
    within_step: 10
    workflow_reference: "../debug.md"
    checkpoint:
      enabled: true
      prompt: |
        WORKFLOW CHECKPOINT - Debug Complete
        Root Cause: {root_cause} | Fix: {fix_status}
        Continue with Step 10? [Y/n/review]
      options:
      - { key: "Y", action: "retry_task" }
      - { key: "n", action: "pause" }
      - { key: "review", action: "show_debug_report" }

# ─────────────────────────────────────────────────────────────────
# CHECKPOINT PROTOCOL
# ─────────────────────────────────────────────────────────────────
checkpoint_protocol:
  display_format: "WORKFLOW CHECKPOINT - {checkpoint_title} | {checkpoint_content} | Progress: {progress_display}"
  interactive_behavior: { pause_for_confirmation: true, require_explicit_response: true }

interactive_research_prompt:
  trigger_condition: "confidence < 60 AND NOT :with-research flag"
  behavior: "ask_user"
  prompt: |
    Technical uncertainty detected (confidence: {confidence_score}%)
    A) Yes - Run research workflow
    B) No - Proceed directly
    C) Review - Show uncertainty details

development_philosophy:
  principle: "Quality first, velocity second"
  approach: "Complete lifecycle with user-validated checkpoints"
  mandate: "Plan thoroughly, review with user, implement carefully, verify continuously"

# ─────────────────────────────────────────────────────────────────
# USER INPUTS
# ─────────────────────────────────────────────────────────────────
user_inputs:
  spec_folder: "[SPEC_FOLDER] - Spec folder path. Leave empty to auto-create next available."
  context: "[CONTEXT] - Background info, constraints, existing docs."
  issues: "[ISSUES] - Known issues or concerns."
  request: "[REQUEST] - Complete work description. REQUIRED."
  environment: "[STAGING LINK] - Staging/production URL for browser testing."
  scope: "[FILES] - Files/folders to work with."

# ─────────────────────────────────────────────────────────────────
# FIELD HANDLING
# ─────────────────────────────────────────────────────────────────
field_handling:
  spec_id:
    derive_from: "spec_folder path using pattern specs/{NNN}, specs/{NNN-name}, or specs/{NNN-parent}/{NNN-phase} (phase child — use parent NNN as spec_id)"
    fallback: "Extract numeric portion or use timestamp if extraction fails"
  defaults: { spec_folder_empty: "Auto-create specs/{NNN} from highest +001", context_empty: "Infer from [REQUEST], [STAGING LINK], and codebase exploration", issues_empty: "Investigate and discover during workflow", environment_empty: "Skip browser testing steps", scope_empty: "Use scope_policy.default" }
  phase_folder_awareness:
    note: "[SPEC_FOLDER] may be a phase child path (e.g., specs/003-name/001-phase/). When Option E is selected or --phase-folder is provided, spec_id derives from the parent folder NNN, not the child NNN. Predecessor validation required for non-first phases."
    path_pattern: "specs/{NNN-parent}/{NNN-phase}/"
  scope_policy: { default: "specs/**", rule: "Limit file operations to scope when provided" }

# ─────────────────────────────────────────────────────────────────
# DOCUMENTATION LEVELS
# ─────────────────────────────────────────────────────────────────
documentation_levels:
  level_1_baseline:
    name: "Level 1 (Baseline)"
    required_files: [spec.md, plan.md, tasks.md]
    loc_guidance: "<100 LOC"
    use_case: "Simple changes, bug fixes"
  level_2_verification:
    name: "Level 2 (Verification)"
    required_files: [spec.md, plan.md, tasks.md, checklist.md]
    loc_guidance: "100-499 LOC"
    use_case: "Medium features, refactoring"
  level_3_full:
    name: "Level 3 (Full)"
    required_files: [spec.md, plan.md, tasks.md, checklist.md, decision-record.md]
    loc_guidance: ">=500 LOC"
    use_case: "Complex features, architecture changes"
  level_selection:
    note: "LOC thresholds are SOFT GUIDANCE - choose level based on complexity and risk"
    default: "Level 1 for simple tasks, escalate based on analysis"

# ─────────────────────────────────────────────────────────────────
# AVAILABLE TEMPLATES
# ─────────────────────────────────────────────────────────────────
available_templates:
  default_level: level_2
  level_1:
    spec: .opencode/skill/system-spec-kit/templates/level_1/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_1/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_1/tasks.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_1/implementation-summary.md
  level_2:
    spec: .opencode/skill/system-spec-kit/templates/level_2/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_2/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_2/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_2/checklist.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_2/implementation-summary.md
  level_3:
    spec: .opencode/skill/system-spec-kit/templates/level_3/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3/implementation-summary.md
  level_3_plus:
    spec: .opencode/skill/system-spec-kit/templates/level_3+/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3+/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3+/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3+/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3+/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3+/implementation-summary.md
  shared:
    research: .opencode/skill/system-spec-kit/templates/research.md
    handover: .opencode/skill/system-spec-kit/templates/handover.md
    debug_delegation: .opencode/skill/system-spec-kit/templates/debug-delegation.md

# ─────────────────────────────────────────────────────────────────
# PARALLEL DISPATCH CONFIGURATION
# ─────────────────────────────────────────────────────────────────
parallel_dispatch_config:
  enabled: true
  scoring: { domain_count: 0.35, file_count: 0.25, loc_estimate: 0.15, parallel_opportunity: 0.20, task_type: 0.05 }
  thresholds: { direct_max: 20, ask_min: 20, min_domains: 2 }
  session_preference_s: 3600
  override_phrases:
    direct: [ "proceed directly", "handle directly", "skip parallel", "skip agents" ]
    parallel: [ "use parallel", "dispatch agents", "parallelize", "use agents" ]
    auto: [ "auto-decide", "auto mode", "decide for me" ]
  eligible_phases: [step_3_specification, step_6_planning, step_8_analysis, step_10_development]

# ─────────────────────────────────────────────────────────────────
# MULTI-AGENT DISPATCH CONFIGURATION
# ─────────────────────────────────────────────────────────────────
multi_agent_config:
  enabled: true
  dispatch_modes:
    single: { id: A, label: "Single Agent", agents: 1, model: opus }
    multi_small:
      id: B
      label: "Multi-Agent (1+2)"
      orchestrator: { model: opus, role: coordinator }
      workers:
        - { role: architecture_explorer, focus: "Project Structure Analysis", step: 6 }
        - { role: feature_explorer, focus: "Feature Pattern Analysis", step: 6 }
    multi_large:
      id: C
      label: "Multi-Agent (1+3)"
      orchestrator: { model: opus, role: coordinator }
      workers:
        - { role: architecture_explorer, focus: "Project Structure Analysis", step: 6 }
        - { role: feature_explorer, focus: "Feature Pattern Analysis", step: 6 }
        - { role: dependency_explorer, focus: "Dependency and Test Analysis", step: 6 }
  fallback: { timeout_s: 60, on_timeout: "continue with available", on_all_fail: "single-agent mode" }

# ─── AGENT AVAILABILITY (conditional — not instructions) ──────────
# These entries define WHICH agent to use IF a workflow step calls for it.
# Do NOT dispatch agents based on reading this section.
# Agents are activated ONLY when their designated step is executing.
agent_availability:
  research:
    available_at_step: "Phase 3 (if :with-research OR confidence < 60%)"
    condition: "ONLY dispatch when :with-research flag is set OR confidence < 60% during planning"
    agent_file: "[runtime_agent_path]/research.md"
    fallback: "general"
    not_for: "proactive research or pre-step investigation"
  speckit:
    available_at_step: 3
    condition: "ONLY dispatch when Step 3 is actively executing"
    agent_file: "[runtime_agent_path]/speckit.md"
    model: opus
    fallback: "general"
    not_for: "reviewing this workflow prompt or any pre-step activity"
  review:
    available_at_step: 11
    condition: "ONLY dispatch when Step 11 is actively executing and all prior steps are completed"
    agent_file: "[runtime_agent_path]/review.md"
    fallback: "general"
    blocking: true
    on_block: "P0 items incomplete. Address before completion."
    dual_phase:
      phase_a: { mode: 2, name: "Pre-Commit code review", blocking: false }
      phase_b: { mode: 4, name: "Gate Validation", blocking: true }
    not_for: "reviewing this workflow prompt, reviewing the command, or any pre-step validation"
  debug:
    available_at_step: 10
    condition: "ONLY dispatch when failure_count >= 3 during Step 10 development"
    agent_file: "[runtime_agent_path]/debug.md"
    fallback: "general-purpose"
    failure_tracking: { counter: "task_failure_count", reset_on: "new_task", threshold: 3 }
    on_threshold_auto_debug: "auto_dispatch_debug"
    on_threshold_else: "Suggest: A) Dispatch debug B) Continue manually C) Skip task D) Pause"
    not_for: "proactive debugging, pre-step investigation, or reviewing this workflow"
  handover:
    available_at_step: 14
    condition: "ONLY dispatch when user explicitly requests handover at Step 14"
    agent_file: "[runtime_agent_path]/handover.md"
    fallback: "general"
    not_for: "automatic handover, pre-step context saving, or premature session ending"

# ─────────────────────────────────────────────────────────────────
# CONFIDENCE CHECKPOINTS
# ─────────────────────────────────────────────────────────────────
confidence_checkpoints:
  enabled: true
  key_steps: [1, 3, 6, 10, 14]
  thresholds: { high: 80, medium: 40, low: 0 }
  protocol: ">=80%: Proceed with evidence | 40-79%: Proceed with caution | <40%: STOP and ask A/B/C"

# ─────────────────────────────────────────────────────────────────
# QUALITY GATES
# ─────────────────────────────────────────────────────────────────
quality_gates:
  enabled: true
  pre_execution:
    location: "Before Step 1"
    threshold: 70
    blocking: hard
    checks:
      - { id: feature_description, points: 30 }
      - { id: spec_path_valid, points: 30 }
      - { id: execution_mode_set, points: 20 }
      - { id: memory_context, points: 20 }
    on_fail: "Pre-execution gate below threshold. Missing: {missing_checks}. Hard block."
  planning_gate:
    location: "Between Step 7 and Step 8"
    threshold: 70
    blocking: hard
    critical: true
    checks:
      - { id: spec_exists, points: 20 }
      - { id: spec_no_clarification, points: 5 }
      - { id: plan_exists, points: 20 }
      - { id: plan_has_approach, points: 5 }
      - { id: tasks_exists, points: 20 }
      - { id: tasks_has_format, points: 5 }
      - { id: checklist_verified, points: 15 }
      - { id: review_approval, points: 10 }
    on_fail: "PLANNING GATE BLOCKED ({score}/100, need 70). Missing: {missing_checks}. HALTED."
    review_integration: { blocking: true, on_review_fail: "P0 items blocking. Address before implementation." }
  post_execution:
    location: "After Step 12"
    threshold: 70
    blocking: hard
    checks:
      - { id: tasks_complete, points: 30 }
      - { id: summary_exists, points: 25 }
      - { id: summary_sections, points: 15 }
      - { id: memory_saved, points: 20 }
      - { id: validation_passed, points: 10 }
    on_fail: "Post-execution gate below threshold. Missing: {missing_checks}. Complete before done."

# ─────────────────────────────────────────────────────────────────
# CIRCUIT BREAKER
# ─────────────────────────────────────────────────────────────────
circuit_breaker:
  enabled: true
  thresholds: { failures: 3, recovery_s: 60, success_to_close: 1 }
  states: { CLOSED: dispatch_to_agent, OPEN: use_fallback, HALF_OPEN: test_single }
  agents: { research: { fallback: general }, speckit: { fallback: general }, review: { fallback: general, preserve: [blocking] } }
  logging: { on_state_change: true, on_fallback_used: true, include_failure_details: true }

# ─────────────────────────────────────────────────────────────────
# CONFIDENCE & CLARIFICATION FRAMEWORK
# ─────────────────────────────────────────────────────────────────
confidence_framework:
  mode_note: "Interactive mode integrates confidence checks with user approval"
  thresholds:
    high: { range: "80-100%", action: "Proceed with citable source" }
    medium: { range: "40-79%", action: "Proceed with caution, document assumptions" }
    low: { range: "0-39%", action: "STOP - Ask clarification with A/B/C options" }
  scoring_weights: { requirements_clarity: 0.25, api_design: 0.15, state_flow: 0.15, type_safety: 0.10, performance: 0.10, accessibility: 0.10, tooling_risk: 0.15 }
  reply_format: ["Confidence: NN%", "Top factors: 2-3 bullets", "Next action"]
  escalation: { timebox_minutes: 10, failed_threshold: 2, action: "Present options to user with current findings" }
  interactive_integration: "Confidence checks are surfaced at user checkpoints"

# ─────────────────────────────────────────────────────────────────
# REQUEST ANALYSIS FRAMEWORK
# ─────────────────────────────────────────────────────────────────
request_analysis_framework:
  solution_flow: [parse_request, gather_context, identify_approach, validate_choice, clarify_if_needed, scope_check, execute]
  design_principles:
    - "KISS: Use existing patterns, direct solution > clever complexity"
    - "Evidence-Based: Cite sources [SOURCE: file:lines] or UNKNOWN"
    - "Effectiveness: Performant + Maintainable + Concise, solve ONLY stated problem"
  pre_change_validation: [simplest_solution, scope_discipline, spec_folder_created, read_files_first, clear_success_criteria, confidence_80_plus, sources_cited, user_approval, checklist_verified_L2_plus]

# ─────────────────────────────────────────────────────────────────
# WORKFLOW ENFORCEMENT
# ─────────────────────────────────────────────────────────────────
workflow_enforcement:
  mode: strict
  step_order: sequential_mandatory
  skip_allowed: false
  phase_gate:
    location: "Between Step 7 and Step 8"
    requirements:
    - "spec.md exists and has no [NEEDS CLARIFICATION] markers"
    - "plan.md exists with technical approach"
    - "tasks.md exists with all tasks listed"
    action_if_failed: "STOP and return to incomplete step"
  step_completion_rule: |
    FOR EACH STEP: Execute ALL activities → Verify ALL outputs → Mark step complete → THEN proceed
    NEVER skip a step. NEVER proceed without marking previous complete. NEVER jump to code before Step 8.
  critical_steps:
    step_10_development:
      enforcement: "MUST mark tasks [x] in tasks.md as completed"
      verification: "Count [x] vs [ ] - all must be [x]"
    step_11_checklist_verify:
      enforcement: "MUST verify all P0/P1 checklist items (Level 2+)"
      verification: "All P0 items [x], P1 either [x] or deferred with approval"
    step_12_completion:
      enforcement: "MUST create implementation-summary.md"
      verification: "File must exist in spec folder"

checkpoint_options:
  standard:
  - { label: "Approve", description: "Approve and proceed" }
  - { label: "Review Details", description: "Show more details" }
  - { label: "Modify", description: "Request changes" }
  - { label: "Skip", description: "Skip (if optional)" }

# ─────────────────────────────────────────────────────────────────
# CONTEXT LOADING
# ─────────────────────────────────────────────────────────────────
context_loading:
  trigger: "At workflow START, before Step 1"
  mcp_integration:
    tool: memory_search
    note: "Call MCP tools directly - NEVER through Code Mode"
    parameters: { query: "context for {spec_folder_name}", specFolder: "{spec_folder_path}", anchors: ['summary', 'decisions', 'state'] }
  command_reference: "/memory:context"
  when_to_skip: ["New spec folder (no prior context)", "User says 'skip context' or 'fresh start'"]
  behavior: { if_context_found: "Present context summary to user for confirmation", if_no_context: "Proceed to Step 1" }
  checkpoint:
    question: "Prior context found. Load this context?"
    options:
      - { label: "Yes - Load context", description: "Use prior decisions and state" }
      - { label: "No - Fresh start", description: "Proceed without prior context" }
      - { label: "Review - Show context first", description: "Display context before deciding" }

# ─────────────────────────────────────────────────────────────────
# WORKFLOW
# ─────────────────────────────────────────────────────────────────
workflow:
  step_1_request_analysis:
    purpose: Analyze inputs and define development scope
    activities:
    - Analyze all user inputs thoroughly
    - Define development scope for the spec folder
    - Verify or create spec folder structure
    - Check for existing artifacts
    - Establish development scope
    phase_predecessor_validation:
      trigger: "If [SPEC_FOLDER] path matches specs/{NNN-parent}/{NNN-phase}/ (phase child)"
      skip_if: "First phase (001-*) — no predecessor to check"
      check: "Find previous numbered phase folder (e.g., for 002-*, check 001-*). Predecessor is complete if: implementation-summary.md exists OR all tasks marked [x] in tasks.md"
      on_fail: "HARD BLOCK — predecessor phase not complete. Report status and halt."
      on_pass: "Continue with step_1 activities"
    confidence_checkpoint:
      evaluate_at: "After analyzing all inputs"
      scoring_factors: ["Requirements clarity (0.40)", "Scope definition (0.30)", "Context availability (0.30)"]
      thresholds:
        high_80_plus: { action: "Proceed to Step 2" }
        medium_40_79: { action: "Proceed with caution", requirement: "Document assumptions in spec.md" }
        low_below_40: { action: "STOP - Ask A/B/C clarification", wait_for: "User response" }
    validation: understanding_confirmed
    checkpoint:
      question: "Step 1 Complete: Request analysis finished. How would you like to proceed?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_2_pre_work_review:
    purpose: Review skills folder and project standards
    activities:
    - Read and review AGENTS.md
    - Check skills folder (.opencode/skill/) for relevant coding standards
    - Extract coding standards summary
    - Identify architectural patterns
    - Document project conventions
    required_documents: [AGENTS.md, "Skills folder (if available)"]
    verification: MUST_REVIEW
    validation: principles_established
    checkpoint:
      question: "Step 2 Complete: Skills folder reviewed. How would you like to proceed?"
      use: present_options_to_user
      options: checkpoint_options.standard

  phase_3_research:
    condition: |
      research_triggered = FALSE
      IF ":with-research" in command_flags:
        research_triggered = TRUE; trigger_reason = "explicit_flag"
      ELSE IF confidence_score < 60:
        prompt_user:
          message: |
            Technical uncertainty detected (confidence: {confidence_score}%)
            A) Yes - Run 9-step research workflow before planning
            B) No - Proceed directly to specification
            C) Review - Show me what's uncertain first
          on_A: research_triggered = TRUE
          on_B: research_triggered = FALSE
          on_C: show_uncertainty_details, then re-prompt
    actions:
      if_triggered:
      - log: "Initiating research phase (reason: {trigger_reason})"
      - execute_workflow: "spec_kit_research_confirm.yaml"
      - on_complete: "show_checkpoint"
      if_skipped:
      - log: "Research phase skipped"
      - continue_to: "step_3"

  step_3_specification:
    purpose: Create comprehensive feature specification
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs]
      on_parallel_dispatch:
        agents:
        - { name: "spec_explorer", focus: "Existing specifications and patterns" }
        - { name: "requirement_analyzer", focus: "Similar features and requirements" }
      fallback: "Proceed with activities below"
    activities:
    - Run create.sh script (scripts/spec/create.sh)
    - Estimate complexity and select documentation level using progressive enhancement:
      - "Level 1 (Baseline): <100 LOC - spec.md + plan.md + tasks.md"
      - "Level 2 (Verification): 100-499 LOC - Level 1 + checklist.md"
      - "Level 3 (Full): >=500 LOC - Level 2 + decision-record.md"
    - Load and fill spec.md
    - Generate functional requirements
    - Define success criteria
    outputs:
    - spec.md: acceptance_criteria
    template: .opencode/skill/system-spec-kit/templates/level_2/spec.md
    confidence_checkpoint:
      evaluate_at: "After drafting spec.md content"
      scoring_factors: ["Requirements completeness (0.35)", "Acceptance criteria clarity (0.35)", "Technical feasibility (0.30)"]
      thresholds:
        high_80_plus: { action: "Finalize spec.md and proceed to Step 4" }
        medium_40_79: { action: "Add [NEEDS CLARIFICATION] markers to uncertain sections" }
        low_below_40: { action: "STOP - Ask clarification before finalizing spec", wait_for: "User response" }
    validation: spec_complete
    checkpoint:
      question: "Step 3 Complete: Specification created. Review spec.md?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_4_clarification:
    purpose: Resolve ambiguities and clarify requirements
    activities:
    - Extract [NEEDS CLARIFICATION] markers (max 3)
    - Research codebase for patterns
    - Resolve ambiguities through investigation
    - Update spec.md with clarifications
    - Document assumptions
    outputs: [resolved_ambiguities, clarified_requirements, updated_spec]
    validation: requirements_clear
    checkpoint:
      question: "Step 4 Complete: Requirements clarified. How would you like to proceed?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_5_quality_checklist:
    purpose: Generate validation checklist AND USE FOR ACTIVE VERIFICATION (Level 2+ requirement)
    level_requirement: "Level 2+ (Verification and Full)"
    activities:
    - Check documentation level - skip for Level 1, MANDATORY for Level 2+
    - Load checklist.md template
    - Generate domain-specific validation items with priorities (P0/P1/P2)
    - Create checklist file
    - "FOR EACH ITEM: Verify condition → Mark [x] with evidence → If not met: document blocker/deferral"
    - Ensure ALL P0 items are complete (HARD BLOCKER)
    - Ensure ALL P1 items complete or user-approved deferral
    - Document P2 deferrals with reasons
    verification_protocol:
      p0_handling: "BLOCKER - Cannot proceed without completion"
      p1_handling: "Required - Complete or get user approval to defer"
      p2_handling: "Optional - Can defer with documented reason"
    outputs:
    - quality_checklist: generated
    - checklist_status: pass_or_fail
    - p0_status: "all_complete or blocked"
    template: .opencode/skill/system-spec-kit/templates/level_2/checklist.md
    validation: checklist_verified_and_marked
    checkpoint:
      question: "Step 5 Complete: Checklist verified. How would you like to proceed?"
      use: present_options_to_user
      options:
      - { label: "Proceed", description: "Continue to planning" }
      - { label: "Review Verification", description: "Show checklist details" }
      - { label: "Address Blockers", description: "Fix P0/P1 blockers first" }

  step_6_planning:
    purpose: Create technical plan with implementation approach

    parallel_dispatch_note: |
      Dispatches 4 parallel agents via Task tool: Architecture, Feature, Dependency, Test Explorer.
      Parallel dispatch is integral to this phase - no additional question asked.

    inline_parallel_exploration:
      execution: { tool: Task, subagent_type: context, model: opus, parallel: true }
      agents:
        architecture_explorer:
          focus: "Project structure, entry points, component connections"
          prompt: |
            Explore codebase architecture for: {task_description}
            Return: 1) Architecture hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        feature_explorer:
          focus: "Similar features, related patterns"
          prompt: |
            Explore codebase for similar features/patterns for: {task_description}
            Return: 1) Similar features hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        dependency_explorer:
          focus: "Imports, modules, affected areas"
          prompt: |
            Explore dependencies and integration points for: {task_description}
            Return: 1) Affected modules hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        test_explorer:
          focus: "Test patterns, testing infrastructure"
          prompt: |
            Explore test patterns and testing infrastructure.
            Return: 1) Testing hypothesis 2) Full test file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
      verification:
        approach:
        - "Read each file identified by @context agents"
        - "Verify or refute each hypothesis"
        - "Cross-reference findings across agents"
        - "Build complete mental model"
        - "Resolve conflicting hypotheses"
      outputs: [architecture_findings, feature_findings, dependency_findings, test_findings, verified_mental_model]
      fallback: { on_failure: "Use inline planning activities below" }

    activities:
    - Run check-prerequisites.sh --json --paths-only
    - Load plan.md
    - Fill Technical Context
    - Fill Constitution Check section
    - Phase 0: Generate research.md to resolve unknowns
    - Phase 1: Define component structure and interfaces
    - Generate Testing Strategy
    - Generate Success Metrics
    - Import Risk Matrix from spec
    - Generate Dependencies Tables
    - Generate Phase 2-4 outlines
    outputs:
    - plan.md: technical_approach
    - research.md: resolved_unknowns
    template: .opencode/skill/system-spec-kit/templates/level_2/plan.md
    confidence_checkpoint:
      evaluate_at: "After drafting plan.md content"
      scoring_factors: ["Technical approach clarity (0.30)", "Risk identification (0.25)", "Dependency mapping (0.25)", "Pattern alignment (0.20)"]
      thresholds:
        high_80_plus: { action: "Finalize plan.md and proceed to Step 7", cite: "Document key sources in plan.md" }
        medium_40_79: { action: "Proceed but flag uncertainties", requirement: "Add RISK markers" }
        low_below_40: { action: "STOP - Request research spike or clarification", wait_for: "User decision" }
      escalation: { trigger: "2 failed attempts OR 10 minutes", action: "Present options to user" }
    validation: approach_defined
    checkpoint:
      question: "Step 6 Complete: Technical plan created. Review plan.md?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_6_5_checkpoint_planning:
    purpose: Save context checkpoint after planning phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to planning milestone for session recovery
    - Preserve planning decisions, exploration findings, and technical approach
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - planning phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__planning_complete.md"
    validation: checkpoint_saved

  step_7_task_breakdown:
    purpose: Break plan into executable tasks (Level 1+ requirement)
    level_requirement: "Level 1+ (Baseline - required at all levels)"
    activities:
    - Load plan.md for tech stack and architecture
    - Load spec.md for user stories and priorities
    - Generate tasks organized by user story
    - Create dependency graph
    - Mark parallel-executable tasks with [P]
    - Define task phases
    - Generate time estimates
    - Create tasks.md (required at all levels)
    outputs:
    - tasks.md: implementation_breakdown
    template: .opencode/skill/system-spec-kit/templates/level_2/tasks.md
    validation: tasks_documented
    checkpoint:
      question: "Step 7 Complete: Tasks broken down. Review tasks.md?"
      use: present_options_to_user
      options: checkpoint_options.standard

    phase_gate_checkpoint:
      trigger: "After Step 7 completes"
      action: |
        STOP and verify Phase Gate:
        1. spec.md exists → If not, return to Step 3
        2. plan.md exists → If not, return to Step 6
        3. tasks.md exists → If not, this step failed
        4. No [NEEDS CLARIFICATION] in spec.md
        5. Mark "PHASE GATE: PASSED"
        6. ONLY THEN proceed to Step 8
      enforcement: HARD_BLOCK

  step_8_analysis:
    purpose: Verify consistency across all artifacts
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs, analysis]
      complexity_boost: 10
      on_parallel_dispatch:
        agents:
        - { name: "consistency_analyzer", focus: "Cross-artifact consistency and requirement coverage" }
        - { name: "gap_detector", focus: "Missing requirements, underspecification, edge cases" }
      fallback: "Proceed with activities below"
    activities:
    - Build requirements inventory
    - Build task coverage mapping
    - Run consistency checks
    - Generate gap analysis
    outputs: [consistency_report, coverage_verification]
    validation: consistency_verified
    checkpoint:
      question: "Step 8 Complete: Consistency analysis done. How would you like to proceed?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_9_implementation_check:
    purpose: Verify all prerequisites for implementation
    activities:
    - Run check-prerequisites.sh --json --require-tasks
    - Verify environment ready
    - Check API endpoints accessible
    - Verify dependencies loaded
    - Confirm no blockers
    checks: { prerequisites: verified, blockers: none, environment: ready }
    validation: prerequisites_verified
    checkpoint:
      question: "Step 9 Complete: Ready to implement. Proceed with development?"
      use: present_options_to_user
      options:
      - { label: "Start Development", description: "Begin implementation" }
      - { label: "Review Plan", description: "Review technical plan" }
      - { label: "Hold", description: "Pause before implementation" }

  step_9_5_preflight:
    name: "PREFLIGHT Capture"
    purpose: "Capture epistemic baseline before implementation"
    tool: "task_preflight"
    parameters: "specFolder, taskId, knowledgeScore, uncertaintyScore, contextScore"
    skip_conditions: ["Less than 10 LOC change", "User says skip preflight"]
    checkpoint: { type: "user_checkpoint", message: "Epistemic scores captured. Continue?" }

  step_10_development:
    purpose: Execute implementation following task plan
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, testing]
      complexity_boost: 15
      on_parallel_dispatch:
        agents:
        - { name: "implementation_agent", focus: "Core implementation tasks from tasks.md" }
        - { name: "test_agent", focus: "Test implementation and validation" }
        warning: "Development tasks may have dependencies - verify task order"
      fallback: "Proceed with activities below"

    debug_integration:
      failure_tracking: { enabled: true, counter_name: "task_failure_count", reset_on: "new_task", threshold: 3 }
      on_threshold_reached:
        if_auto_debug_flag:
          action: "auto_dispatch_debug"
        else:
          action: "prompt_user"
          prompt: |
            Multiple fix attempts failed (3+) for task {current_task_id}
            A) Yes - Dispatch debug agent
            B) No - Continue debugging manually
            C) Skip task - Move to next task
            D) Pause - Stop workflow and review
          on_A: dispatch_debug
          on_B: reset_failure_count, continue
          on_C: mark_task_skipped, next_task
          on_D: pause_workflow
      debug_dispatch:
        subagent_type: "general-purpose"
        timeout_ms: 120000
        context_includes: [error_message, affected_files, previous_attempts, current_task_id]
        on_complete: "show_checkpoint"

    activities:
    - Parse tasks.md structure
    - Execute phase by phase
    - Setup first (structure, dependencies, config)
    - Follow TDD approach where applicable
    - Core development (models, services, endpoints)
    - Integration work (database, middleware, logging)
    - Update task checklist progressively (mark [X])
    - Log progress after each task
    approach: incremental_implementation_with_reviews
    requirements:
    - follow: Check skills folder for coding standards
    - update: task_checklist_progressively
    - test: before_commit
    - validate: continuously
    confidence_checkpoint:
      evaluate_at: "Before each significant code change"
      per_task_assessment:
        scoring_factors: ["Implementation clarity (0.35)", "Pattern alignment (0.30)", "Risk awareness (0.35)"]
        thresholds:
          high_80_plus: { action: "Implement task, mark [x]" }
          medium_40_79: { action: "Implement with extra validation", requirement: "Add inline comments" }
          low_below_40: { action: "STOP - Do not implement uncertain code", wait_for: "Resolution" }
    validation: development_complete
    checkpoint:
      question: "Step 10 Complete: Development finished. Review implementation?"
      use: present_options_to_user
      options:
      - { label: "Review Code", description: "Show code changes" }
      - { label: "Run Tests", description: "Execute test suite" }
      - { label: "Continue", description: "Proceed to completion" }

    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY: Read tasks.md → Count [ ] vs [x] → ALL must be [x] and code works → THEN mark complete
      failure_action: "Continue development - do not proceed to Step 11"

  step_10_5_checkpoint_development:
    purpose: Save context checkpoint after development phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to development milestone for session recovery
    - Preserve implementation decisions, code changes, and debugging insights
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - development phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__development_complete.md"
    validation: checkpoint_saved

  step_11_checklist_verify:
    purpose: Verify all P0/P1 checklist items are complete before claiming completion
    blocking: true
    level_requirement: "Level 2+"
    activities:
    - Load checklist.md from spec folder
    - Verify ALL P0 items are marked [x] with evidence
    - Verify ALL P1 items are either marked [x] or have documented user approval to defer
    - P2 items may be deferred without approval
    - Document verification results with evidence format
    evidence_format: "- [x] Task description [EVIDENCE: file.js:45-67 - implementation verified]"
    evidence_log_pattern: "[E:filename]"
    p0_enforcement:
      blocking: true
      on_incomplete: "P0 ITEMS INCOMPLETE - Cannot proceed. WORKFLOW HALTED."
    p1_enforcement:
      blocking: soft
      allow_deferral: true
      on_incomplete: "P1 items incomplete. A) Complete remaining B) Document deferral and proceed"
    outputs: [checklist_verification_report, evidence_documentation]
    validation: all_p0_complete
    checkpoint:
      question: "Step 11 Complete: All P0/P1 checklist items verified. Proceed to completion?"
      use: present_options_to_user
      options: checkpoint_options.standard

  step_11_5_postflight:
    name: "POSTFLIGHT Capture"
    purpose: "Capture learning delta after implementation"
    tool: "task_postflight"
    parameters: "specFolder, taskId, knowledgeScore, uncertaintyScore, contextScore"
    skip_conditions: ["Less than 10 LOC change", "No PREFLIGHT was captured"]
    checkpoint: { type: "user_checkpoint", message: "Epistemic scores captured. Continue?" }

  step_12_completion:
    purpose: Generate implementation summary
    activities:
    - Verify all tasks completed
    - Validate tests pass
    - Confirm implementation follows plan
    - Generate implementation-summary.md
    - Update all task status
    summary_document:
      location: "[SPEC_FOLDER]/implementation-summary.md"
      required_sections: [files_modified_created, verification_steps_taken, deviations_from_plan, skill_updates, recommended_next_steps, browser_testing_results]
    verification_summary:
      checklist_verification:
        required: true
        must_include: [total_items_count, p0_status, p1_status, deferred_p2_items, checklist_link]
    validation: implementation_complete
    checkpoint:
      question: "Step 12 Complete: Implementation summary generated. Review summary?"
      use: present_options_to_user
      options: checkpoint_options.standard

    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY: implementation-summary.md exists with all required sections → THEN mark complete
      required_file: "[SPEC_FOLDER]/implementation-summary.md"
      failure_action: "Create implementation-summary.md before proceeding"

  step_13_save_context:
    purpose: Save conversation context
    activities:
    - Invoke system-spec-kit skill
    - Preserve development decisions
    - Preserve debugging insights
    - Preserve code changes
    - Index memory file for immediate search availability
    memory_creation:
      enforcement: HARD_BLOCK
      method: "MUST use generate-context.js script"
      command: "node .opencode/skill/system-spec-kit/scripts/dist/memory/generate-context.js [spec-folder-path]"
      forbidden: { tools: [Write, Edit], action: "NEVER manually create memory files", paths: ["*/memory/*.md", "specs/*/memory/*"] }
      violation_recovery: "DELETE manual file → run generate-context.js → verify ANCHORs → index via memory_save"
    tool_invocation:
      command: 'Read(".opencode/skill/system-spec-kit/SKILL.md")'
    outputs:
    - context_file: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md"
    validation: context_saved_successfully
    checkpoint:
      question: "Step 13 Complete: Context saved. Proceed to handover check?"
      use: present_options_to_user
      options:
      - { label: "Continue", description: "Proceed to handover check" }
      - { label: "Skip Handover", description: "Complete without handover" }

    post_save_indexing:
      mcp_tool: memory_save
      invocation: 'spec_kit_memory_memory_save({ filePath: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md" })'
      critical_note: "Call semantic memory MCP DIRECTLY - NEVER through Code Mode"
      when: "Immediately after memory file is written to disk"

    anchor_requirements:
      enforcement: MANDATORY
      minimum_anchors: 2
      pattern: "[context-type]-[keywords]-[spec-number]"
      format: "<!-- ANCHOR:ID --> content <!-- /ANCHOR:ID -->"
      required_sections:
      - { context_type: "general", section: "Session summary", example_id: "GENERAL-SESSION-SUMMARY-{spec#}" }
      - { context_type: "decision", section: "Key decisions", example_id: "DECISION-{topic}-{spec#}" }
      optional_sections:
      - { context_type: "implementation", example_id: "IMPLEMENTATION-{feature}-{spec#}" }
      - { context_type: "files", example_id: "FILES-{spec#}" }
      benefit: "93% token savings on anchor-based retrieval"

    importance_tier:
      assign: important
      rationale: "Complete workflow represents significant implementation work"
      tier_reference: "constitutional > critical > important > normal > temporary > deprecated"

  step_14_handover_check:
    purpose: Offer session handover before workflow completion
    activities:
    - Check if user needs session continuity documentation
    - Offer to run /spec_kit:handover for comprehensive handover
    checkpoint:
      question: "Step 14: Would you like to create a handover document for session continuity?"
      use: present_options_to_user
      options:
      - { label: "Run Handover", description: "Run /spec_kit:handover" }
      - { label: "Skip", description: "Complete without handover" }
    note: "Handover is optional but recommended for complex implementations"
    validation: handover_offered

# ─────────────────────────────────────────────────────────────────
# WORKFLOW TERMINATION
# ─────────────────────────────────────────────────────────────────
termination:
  after_step: 14
  message: "SpecKit workflow completed successfully."

# ─────────────────────────────────────────────────────────────────
# INTERACTIVE EXECUTION GUIDANCE
# ─────────────────────────────────────────────────────────────────
interactive_execution:
  principle: "Execute workflow steps with user approval at each checkpoint"
  checkpoint_behavior: "Complete step → Present results → Present options → Wait for response → Proceed or modify"
  user_feedback_handling: { approve: "Proceed", review: "Show details", modify: "Accept changes, re-execute", skip: "Skip optional step" }

# ─────────────────────────────────────────────────────────────────
# ERROR RECOVERY
# ─────────────────────────────────────────────────────────────────
error_recovery:
  step_validation_fails: "Review requirements, ask clarifying questions, retry step"
  user_rejects_approach: "Present alternatives, modify plan, document decision"
  tests_fail: "Debug, fix, re-run before marking complete"
  prerequisites_insufficient: "Return to prior phase or ask user"
  environment_unavailable: "Skip browser testing, document limitation"

# ─────────────────────────────────────────────────────────────────
# QUALITY STANDARDS
# ─────────────────────────────────────────────────────────────────
quality_standards:
  documentation: [production_ready_examples, defensive_programming, error_handling, comprehensive_tests]
  code_examples: [working_snippets, error_handling, performance_optimized, accessible, browser_compatible]
  analysis_depth: [edge_cases, failure_modes, recovery_strategies, monitoring]

# ─────────────────────────────────────────────────────────────────
# SUCCESS CRITERIA
# ─────────────────────────────────────────────────────────────────
success:
  specification: [requirements_defined, acceptance_criteria, approach_planned, dependencies_identified]
  implementation: [code_follows_standards, tests_pass, browser_validated, performance_acceptable]
  documentation: [spec_folder_complete, summary_created, deviations_documented, context_saved]
  quality: [checklist_validated, no_regressions, functionality_preserved, standards_maintained]

# ─────────────────────────────────────────────────────────────────
# RULES
# ─────────────────────────────────────────────────────────────────
rules:
  ALWAYS:
  - follow_workflow_sequence
  - document_all_changes
  - validate_before_completion
  - use_browser_for_staging_analysis
  - pause_at_checkpoints_for_approval
  - respect_user_feedback
  - limit_context_to_active_scope
  - use_checklist_for_verification_level_2_plus
  - mark_checklist_items_with_evidence
  - complete_all_p0_items_before_done
  - get_user_approval_for_p1_deferrals
  NEVER:
  - skip_workflow_steps
  - ignore_blockers
  - submit_without_validation
  - proceed_without_user_approval
  - ignore_user_modification_requests
  - claim_completion_without_checklist_verification_level_2_plus
  - skip_p0_checklist_items
  - defer_p1_items_without_user_approval
