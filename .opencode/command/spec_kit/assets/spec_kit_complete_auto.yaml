# ─────────────────────────────────────────────────────────────────
# SMART SPECKIT: COMPLETE WORKFLOW (AUTONOMOUS MODE)
# ─────────────────────────────────────────────────────────────────
role: Expert Developer using Smart SpecKit autonomously
purpose: Spec-driven development with mandatory compliance and autonomous execution
action: Run full SpecKit from spec to implementation with continuous validation

# ─────────────────────────────────────────────────────────────────
# OPERATING MODE
# ─────────────────────────────────────────────────────────────────
operating_mode:
  workflow: sequential_14_step
  workflow_compliance: MANDATORY
  workflow_execution: autonomous
  approvals: none
  tracking: progressive_task_checklists
  validation: continuous_self_validation
  description: |
    Executes the 14-step workflow without step-by-step approval.
    Supports optional chained workflows:
    - :with-research - Run research phase before planning
    - :auto-debug - Auto-dispatch debug agent on 3+ failures
    Checkpoints still pause for confirmation after optional workflows complete.

development_philosophy:
  principle: "Quality first, velocity second"
  approach: "Complete lifecycle with validated checkpoints"
  mandate: "Plan thoroughly, implement carefully, verify continuously, execute autonomously"

optional_workflows:
  research_integration:
    enabled: true
    trigger:
      flag: ":with-research"
      smart_detect: true
      uncertainty_threshold: 60
    insert_point: "after_phase_2"
    workflow_reference: "spec_kit_research_auto.yaml"
    checkpoint:
      enabled: true
      prompt: |
        WORKFLOW CHECKPOINT - Research Complete
        Research phase complete. Created: research.md (17 sections)
        Continue to Step 1 (Request Analysis)? [Y/n/review]
      options:
      - { key: "Y", action: "continue" }
      - { key: "n", action: "pause" }
      - { key: "review", action: "show_output" }

  debug_integration:
    enabled: true
    trigger:
      flag: ":auto-debug"
      auto_suggest: true
      failure_threshold: 3
    within_step: 10
    workflow_reference: "../debug.md"
    checkpoint:
      enabled: true
      prompt: |
        WORKFLOW CHECKPOINT - Debug Complete
        Root Cause: {root_cause} | Fix: {fix_status}
        Continue with Step 10? [Y/n/review]
      options:
      - { key: "Y", action: "retry_task" }
      - { key: "n", action: "pause" }
      - { key: "review", action: "show_debug_report" }

# ─────────────────────────────────────────────────────────────────
# USER INPUTS
# ─────────────────────────────────────────────────────────────────
user_inputs:
  spec_folder: "[SPEC_FOLDER] - Spec folder path. Leave empty to auto-create next available."
  context: "[CONTEXT] - Background info, constraints, existing docs. Leave empty to infer."
  issues: "[ISSUES] - Known issues or concerns. Leave empty to discover."
  request: "[REQUEST] - Complete work description. REQUIRED."
  environment: "[STAGING LINK] - Staging/production URL. Leave empty to skip browser testing."
  scope: "[FILES] - Files/folders/globs to work with. Leave empty for default scope."

# ─────────────────────────────────────────────────────────────────
# FIELD HANDLING
# ─────────────────────────────────────────────────────────────────
field_handling:
  spec_id:
    derive_from: "spec_folder path using pattern specs/{NNN} or specs/{NNN-name}"
    fallback: "Extract numeric portion or use timestamp if extraction fails"
  defaults: { spec_folder_empty: "Auto-create specs/{NNN} from highest +001", context_empty: "Infer from [REQUEST], [STAGING LINK], and codebase exploration", issues_empty: "Investigate and discover during workflow", environment_empty: "Skip browser testing steps", scope_empty: "Use scope_policy.default" }
  scope_policy: { default: "specs/**", rule: "Limit file operations to scope when provided" }

# ─────────────────────────────────────────────────────────────────
# DOCUMENTATION LEVELS
# ─────────────────────────────────────────────────────────────────
documentation_levels:
  level_1_baseline:
    name: "Level 1 (Baseline)"
    required_files: [spec.md, plan.md, tasks.md]
    loc_guidance: "<100 LOC"
    use_case: "Simple changes, bug fixes"
  level_2_verification:
    name: "Level 2 (Verification)"
    required_files: [spec.md, plan.md, tasks.md, checklist.md]
    loc_guidance: "100-499 LOC"
    use_case: "Medium features, refactoring"
  level_3_full:
    name: "Level 3 (Full)"
    required_files: [spec.md, plan.md, tasks.md, checklist.md, decision-record.md]
    loc_guidance: ">=500 LOC"
    use_case: "Complex features, architecture changes"
  level_selection:
    note: "LOC thresholds are SOFT GUIDANCE - choose level based on complexity and risk"
    default: "Level 1 for simple tasks, escalate based on analysis"

# ─────────────────────────────────────────────────────────────────
# AVAILABLE TEMPLATES
# ─────────────────────────────────────────────────────────────────
available_templates:
  default_level: level_2
  level_1:
    spec: .opencode/skill/system-spec-kit/templates/level_1/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_1/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_1/tasks.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_1/implementation-summary.md
  level_2:
    spec: .opencode/skill/system-spec-kit/templates/level_2/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_2/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_2/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_2/checklist.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_2/implementation-summary.md
  level_3:
    spec: .opencode/skill/system-spec-kit/templates/level_3/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3/implementation-summary.md
  level_3_plus:
    spec: .opencode/skill/system-spec-kit/templates/level_3+/spec.md
    plan: .opencode/skill/system-spec-kit/templates/level_3+/plan.md
    tasks: .opencode/skill/system-spec-kit/templates/level_3+/tasks.md
    checklist: .opencode/skill/system-spec-kit/templates/level_3+/checklist.md
    decision_record: .opencode/skill/system-spec-kit/templates/level_3+/decision-record.md
    implementation_summary: .opencode/skill/system-spec-kit/templates/level_3+/implementation-summary.md
  shared:
    research: .opencode/skill/system-spec-kit/templates/research.md
    handover: .opencode/skill/system-spec-kit/templates/handover.md
    debug_delegation: .opencode/skill/system-spec-kit/templates/debug-delegation.md

# ─────────────────────────────────────────────────────────────────
# PARALLEL DISPATCH CONFIGURATION
# ─────────────────────────────────────────────────────────────────
parallel_dispatch_config:
  enabled: true
  scoring: { domain_count: 0.35, file_count: 0.25, loc_estimate: 0.15, parallel_opportunity: 0.20, task_type: 0.05 }
  thresholds: { direct_max: 20, ask_min: 20, min_domains: 2 }
  session_preference_s: 3600
  override_phrases:
    direct: [ "proceed directly", "handle directly", "skip parallel", "skip agents" ]
    parallel: [ "use parallel", "dispatch agents", "parallelize", "use agents" ]
    auto: [ "auto-decide", "auto mode", "decide for me" ]
  eligible_phases: [step_3_specification, step_6_planning, step_8_analysis, step_10_development]

# ─────────────────────────────────────────────────────────────────
# MULTI-AGENT DISPATCH CONFIGURATION
# ─────────────────────────────────────────────────────────────────
multi_agent_config:
  enabled: true
  dispatch_modes:
    single: { id: A, label: "Single Agent", agents: 1, model: opus }
    multi_small:
      id: B
      label: "Multi-Agent (1+2)"
      orchestrator: { model: opus, role: coordinator }
      workers:
        - { role: architecture_explorer, focus: "Project Structure Analysis", step: 6 }
        - { role: feature_explorer, focus: "Feature Pattern Analysis", step: 6 }
    multi_large:
      id: C
      label: "Multi-Agent (1+3)"
      orchestrator: { model: opus, role: coordinator }
      workers:
        - { role: architecture_explorer, focus: "Project Structure Analysis", step: 6 }
        - { role: feature_explorer, focus: "Feature Pattern Analysis", step: 6 }
        - { role: dependency_explorer, focus: "Dependency and Test Analysis", step: 6 }
  fallback: { timeout_s: 60, on_timeout: "continue with available", on_all_fail: "single-agent mode" }

# ─── AGENT AVAILABILITY (conditional — not instructions) ──────────
# These entries define WHICH agent to use IF a workflow step calls for it.
# Do NOT dispatch agents based on reading this section.
# Agents are activated ONLY when their designated step is executing.
agent_availability:
  research:
    available_at_step: "Phase 3 (if :with-research OR confidence < 60%)"
    condition: "ONLY dispatch when :with-research flag is set OR confidence < 60% during planning"
    agent_file: "[runtime_agent_path]/research.md"
    fallback: "general"
    not_for: "proactive research or pre-step investigation"
  speckit:
    available_at_step: 3
    condition: "ONLY dispatch when Step 3 is actively executing"
    agent_file: "[runtime_agent_path]/speckit.md"
    model: opus
    fallback: "general"
    not_for: "reviewing this workflow prompt or any pre-step activity"
  review:
    available_at_step: 11
    condition: "ONLY dispatch when Step 11 is actively executing and all prior steps are completed"
    agent_file: "[runtime_agent_path]/review.md"
    fallback: "general"
    blocking: true
    on_block: "P0 items incomplete. Address before completion."
    dual_phase:
      phase_a: { mode: 2, name: "Pre-Commit code review", blocking: false }
      phase_b: { mode: 4, name: "Gate Validation", blocking: true }
    not_for: "reviewing this workflow prompt, reviewing the command, or any pre-step validation"
  debug:
    available_at_step: 10
    condition: "ONLY dispatch when failure_count >= 3 during Step 10 development"
    agent_file: "[runtime_agent_path]/debug.md"
    fallback: "general-purpose"
    failure_tracking: { counter: "task_failure_count", reset_on: "new_task", threshold: 3 }
    on_threshold_auto_debug: "auto_dispatch_debug"
    on_threshold_else: "Suggest: A) Dispatch debug B) Continue manually C) Skip task D) Pause"
    not_for: "proactive debugging, pre-step investigation, or reviewing this workflow"
  handover:
    available_at_step: 14
    condition: "ONLY dispatch when user explicitly requests handover at Step 14"
    agent_file: "[runtime_agent_path]/handover.md"
    fallback: "general"
    not_for: "automatic handover, pre-step context saving, or premature session ending"

# ─────────────────────────────────────────────────────────────────
# QUALITY GATES
# ─────────────────────────────────────────────────────────────────
quality_gates:
  enabled: true
  pre_execution:
    location: "Before Step 1"
    threshold: 70
    blocking: hard
    checks:
      - { id: feature_description, points: 30 }
      - { id: spec_path_valid, points: 30 }
      - { id: execution_mode_set, points: 20 }
      - { id: memory_context, points: 20 }
    on_fail: "Pre-execution gate below threshold. Missing: {missing_checks}. Hard block."
  planning_gate:
    location: "Between Step 7 and Step 8"
    threshold: 70
    blocking: hard
    critical: true
    checks:
      - { id: spec_exists, points: 20 }
      - { id: spec_no_clarification, points: 5 }
      - { id: plan_exists, points: 20 }
      - { id: plan_has_approach, points: 5 }
      - { id: tasks_exists, points: 20 }
      - { id: tasks_has_format, points: 5 }
      - { id: checklist_verified, points: 15 }
      - { id: review_approval, points: 10 }
    on_fail: "PLANNING GATE BLOCKED ({score}/100, need 70). Missing: {missing_checks}. HALTED."
    review_integration: { blocking: true, on_review_fail: "P0 items blocking. Address before implementation." }
  post_execution:
    location: "After Step 12"
    threshold: 70
    blocking: hard
    checks:
      - { id: tasks_complete, points: 30 }
      - { id: summary_exists, points: 25 }
      - { id: summary_sections, points: 15 }
      - { id: memory_saved, points: 20 }
      - { id: validation_passed, points: 10 }
    on_fail: "Post-execution gate below threshold. Missing: {missing_checks}. Complete before done."

# ─────────────────────────────────────────────────────────────────
# CIRCUIT BREAKER
# ─────────────────────────────────────────────────────────────────
circuit_breaker:
  enabled: true
  thresholds: { failures: 3, recovery_s: 60, success_to_close: 1 }
  states: { CLOSED: dispatch_to_agent, OPEN: use_fallback, HALF_OPEN: test_single }
  agents: { research: { fallback: general }, speckit: { fallback: general }, review: { fallback: general, preserve: [blocking] } }
  logging: { on_state_change: true, on_fallback_used: true, include_failure_details: true }

# ─────────────────────────────────────────────────────────────────
# CONFIDENCE & CLARIFICATION FRAMEWORK
# ─────────────────────────────────────────────────────────────────
confidence_framework:
  thresholds:
    high: { range: "80-100%", action: "Proceed with cited evidence" }
    medium: { range: "40-79%", action: "Proceed with caution, document assumptions" }
    low: { range: "0-39%", action: "STOP - Ask A/B/C clarification" }
  scoring_weights: { requirements_clarity: 0.25, api_design: 0.15, state_flow: 0.15, type_safety: 0.10, performance: 0.10, accessibility: 0.10, tooling_risk: 0.15 }
  reply_format: ["Confidence: NN%", "Top factors: 2-3 bullets", "Next action"]
  escalation: { timebox_minutes: 10, failed_threshold: 2 }

# ─────────────────────────────────────────────────────────────────
# REQUEST ANALYSIS FRAMEWORK
# ─────────────────────────────────────────────────────────────────
request_analysis_framework:
  solution_flow: [parse_request, gather_context, identify_approach, validate_choice, clarify_if_needed, scope_check, execute]
  design_principles:
    - "KISS: Use existing patterns, direct solution > clever complexity"
    - "Evidence-Based: Cite sources [SOURCE: file:lines] or UNKNOWN"
    - "Effectiveness: Performant + Maintainable + Concise, solve ONLY stated problem"
  pre_change_validation: [simplest_solution, scope_discipline, spec_folder_created, read_files_first, clear_success_criteria, confidence_80_plus, sources_cited, user_approval, checklist_verified_L2_plus]

# ─────────────────────────────────────────────────────────────────
# WORKFLOW ENFORCEMENT
# ─────────────────────────────────────────────────────────────────
workflow_enforcement:
  mode: strict
  step_order: sequential_mandatory
  skip_allowed: false
  phase_gate:
    location: "Between Step 7 and Step 8"
    requirements:
    - "spec.md exists and has no [NEEDS CLARIFICATION] markers"
    - "plan.md exists with technical approach"
    - "tasks.md exists with all tasks listed"
    action_if_failed: "STOP and return to incomplete step"
  step_completion_rule: |
    FOR EACH STEP: Execute ALL activities → Verify ALL outputs → Mark step complete → THEN proceed
    NEVER skip a step. NEVER proceed without marking previous complete. NEVER jump to code before Step 8.
  critical_steps:
    step_10_development:
      enforcement: "MUST mark tasks [x] in tasks.md as completed"
      verification: "Count [x] vs [ ] - all must be [x]"
    step_11_checklist_verify:
      enforcement: "MUST verify all P0/P1 checklist items (Level 2+)"
      verification: "All P0 items [x], P1 either [x] or deferred with approval"
    step_12_completion:
      enforcement: "MUST create implementation-summary.md"
      verification: "File must exist in spec folder"

# ─────────────────────────────────────────────────────────────────
# CONTEXT LOADING
# ─────────────────────────────────────────────────────────────────
context_loading:
  trigger: "At workflow START, before Step 1"
  mcp_integration:
    tool: memory_search
    note: "Call MCP tools directly - NEVER through Code Mode"
    parameters: { query: "context for {spec_folder_name}", specFolder: "{spec_folder_path}", anchors: ['summary', 'decisions', 'state'] }
  command_reference: "/memory:context"
  when_to_skip: ["New spec folder (no prior context)", "User says 'skip context' or 'fresh start'"]
  behavior: { if_context_found: "Surface relevant decisions and state", if_no_context: "Proceed to Step 1" }

# ─────────────────────────────────────────────────────────────────
# WORKFLOW
# ─────────────────────────────────────────────────────────────────
workflow:
  step_1_request_analysis:
    purpose: Analyze inputs and define development scope
    spec_folder: "[SPEC_FOLDER] → auto-create if empty"
    context: "[CONTEXT] → infer if empty"
    issues: "[ISSUES] → discover if empty"
    request: "[REQUEST] → REQUIRED"
    environment: "[STAGING LINK] → skip browser testing if empty"
    scope: "[FILES] → default scope if empty"
    activities:
    - Analyze all user inputs thoroughly
    - Define development scope for the spec folder
    - Verify or create spec folder structure
    - Check for existing artifacts
    - Establish development scope
    confidence_checkpoint:
      evaluate_at: "After analyzing all inputs"
      scoring_factors: ["Requirements clarity (0.40)", "Scope definition (0.30)", "Context availability (0.30)"]
      thresholds:
        high_80_plus: { action: "Proceed to Step 2" }
        medium_40_79: { action: "Proceed with caution", requirement: "Document assumptions in spec.md" }
        low_below_40: { action: "STOP - Ask A/B/C clarification", wait_for: "User response" }
    validation: understanding_confirmed

  step_2_pre_work_review:
    purpose: Review skills folder and project standards
    activities:
    - Read and review AGENTS.md (project principles)
    - Check skills folder (.opencode/skill/) for relevant coding standards
    - Extract coding standards summary
    - Identify architectural patterns
    - Document project conventions
    - Identify constraints
    - Verify principle alignment
    required_documents: [AGENTS.md, "Skills folder (if available)"]
    verification: MUST_REVIEW
    validation: principles_established

  phase_3_research:
    condition: |
      research_triggered = FALSE
      IF ":with-research" in command_flags:
        research_triggered = TRUE; trigger_reason = "explicit_flag"
      ELSE IF confidence_score < 60:
        research_triggered = TRUE; trigger_reason = "uncertainty_auto_detected"
    actions:
      if_triggered:
      - log: "Initiating research phase (reason: {trigger_reason})"
      - execute_workflow: "spec_kit_research_auto.yaml"
      - on_complete: "show_checkpoint"
      if_skipped:
      - log: "Research phase skipped (confidence: {confidence_score}%)"
      - continue_to: "step_3"

  step_3_specification:
    purpose: Create comprehensive feature specification
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs]
      on_parallel_dispatch:
        agents:
        - { name: "spec_explorer", focus: "Existing specifications and patterns" }
        - { name: "requirement_analyzer", focus: "Similar features and requirements" }
      fallback: "Proceed with activities below"
    activities:
    - Find highest feature number across all sources
    - Run create.sh script (scripts/spec/create.sh) with calculated number
    - Estimate complexity and select documentation level using progressive enhancement:
      - "Level 1 (Baseline): <100 LOC - spec.md + plan.md + tasks.md"
      - "Level 2 (Verification): 100-499 LOC - Level 1 + checklist.md"
      - "Level 3 (Full): >=500 LOC - Level 2 + decision-record.md"
    - Load spec.md and use as EXACT structure
    - Parse user description and extract key concepts
    - Identify actors, actions, data, constraints
    - Make informed guesses based on context for unclear aspects
    - Fill User Scenarios & Testing section
    - Generate Functional Requirements (testable)
    - Define Success Criteria (measurable, technology-agnostic)
    - Identify Key Entities if data involved
    - For Level 2+, include mandatory checklist.md
    - For Level 3, include decision-record.md with Traceability, Risk Matrix, Rollback Plan
    confidence_checkpoint:
      evaluate_at: "After drafting spec.md content"
      scoring_factors: ["Requirements completeness (0.35)", "Acceptance criteria clarity (0.35)", "Technical feasibility (0.30)"]
      thresholds:
        high_80_plus: { action: "Finalize spec.md and proceed to Step 4" }
        medium_40_79: { action: "Add [NEEDS CLARIFICATION] markers to uncertain sections" }
        low_below_40: { action: "STOP - Ask clarification before finalizing spec", wait_for: "User response" }
    outputs:
    - spec.md: acceptance_criteria
    - location: "[SPEC_FOLDER]/spec.md"
    template: .opencode/skill/system-spec-kit/templates/level_2/spec.md
    validation: spec_complete

  step_4_clarification:
    purpose: Resolve ambiguities and clarify requirements
    activities:
    - Extract all [NEEDS CLARIFICATION] markers from spec
    - Limit to maximum 3 clarifications (prioritize by impact)
    - Make informed guesses for lower-priority items
    - For each clarification, research codebase for patterns
    - Test in browser when staging URL provided
    - Resolve ambiguities through systematic investigation
    - Update spec.md with resolved clarifications
    - Document all assumptions made
    outputs: [resolved_ambiguities, clarified_requirements, updated_spec]
    validation: requirements_clear

  step_5_quality_checklist:
    purpose: Generate validation checklist AND USE FOR ACTIVE VERIFICATION (Level 2+ requirement)
    level_requirement: "Level 2+ (Verification and Full)"
    activities:
    - Check documentation level - skip for Level 1, MANDATORY for Level 2+
    - Load checklist.md template
    - Generate domain-specific validation items with priorities (P0/P1/P2)
    - Create checklist file at FEATURE_DIR/checklist.md
    - "FOR EACH ITEM: Verify condition → Mark [x] with evidence → If not met: document blocker/deferral"
    - Ensure ALL P0 items are complete (HARD BLOCKER)
    - Ensure ALL P1 items complete or user-approved deferral
    - Document P2 deferrals with reasons
    verification_protocol:
      p0_handling: "BLOCKER - Cannot proceed without completion"
      p1_handling: "Required - Complete or get user approval to defer"
      p2_handling: "Optional - Can defer with documented reason"
    outputs:
    - quality_checklist: generated
    - location: "[SPEC_FOLDER]/checklist.md"
    - checklist_status: pass_or_fail
    - p0_status: "all_complete or blocked"
    template: .opencode/skill/system-spec-kit/templates/level_2/checklist.md
    validation: checklist_verified_and_marked

  step_6_planning:
    purpose: Create technical plan with implementation approach

    parallel_dispatch_note: |
      Dispatches 4 parallel agents via Task tool: Architecture, Feature, Dependency, Test Explorer.
      Parallel dispatch is integral to this phase - no additional question asked.

    inline_parallel_exploration:
      execution: { tool: Task, subagent_type: context, model: opus, parallel: true }
      agents:
        architecture_explorer:
          focus: "Project structure, entry points, component connections"
          prompt: |
            Explore codebase architecture for: {task_description}
            Return: 1) Architecture hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        feature_explorer:
          focus: "Similar features, related patterns"
          prompt: |
            Explore codebase for similar features/patterns for: {task_description}
            Return: 1) Similar features hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        dependency_explorer:
          focus: "Imports, modules, affected areas"
          prompt: |
            Explore dependencies and integration points for: {task_description}
            Return: 1) Affected modules hypothesis 2) Full file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
        test_explorer:
          focus: "Test patterns, testing infrastructure"
          prompt: |
            Explore test patterns and testing infrastructure.
            Return: 1) Testing hypothesis 2) Full test file paths 3) Patterns noticed
            Do NOT draw conclusions - just report findings.
      verification:
        approach:
        - "Read each file identified by @context agents"
        - "Verify or refute each hypothesis"
        - "Cross-reference findings across agents"
        - "Build complete mental model"
        - "Resolve conflicting hypotheses"
      outputs: [architecture_findings, feature_findings, dependency_findings, test_findings, verified_mental_model]
      fallback: { on_failure: "Use inline planning activities below" }

    activities:
    - Run check-prerequisites.sh --json --paths-only to get feature paths
    - Load FEATURE_SPEC and AGENTS.md
    - Load plan.md and preserve exact structure
    - Fill Technical Context (mark unknowns as NEEDS CLARIFICATION)
    - Fill Constitution Check section
    - Evaluate gates (ERROR if violations unjustified)
    - Phase 0: Generate research.md to resolve all unknowns
    - Phase 1: Define component structure and interfaces
    - Generate Testing Strategy with test pyramid
    - Generate Success Metrics from spec criteria
    - Import Risk Matrix from spec
    - Generate Dependencies Tables
    - Generate Communication & Review sections
    - Re-evaluate Constitution Check post-design
    - Generate Phase 2-4 outlines (implementation phases)
    outputs:
    - plan.md: technical_approach
    - research.md: resolved_unknowns
    level_1_baseline: [spec.md, plan.md, tasks.md]
    level_2_verification: [checklist.md]
    level_3_full: [decision-record.md]
    decision_records:
      when: significant_technical_decision_needs_documentation
      template: .opencode/skill/system-spec-kit/templates/level_3/decision-record.md
    template: .opencode/skill/system-spec-kit/templates/level_2/plan.md
    confidence_checkpoint:
      evaluate_at: "After drafting plan.md content"
      scoring_factors: ["Technical approach clarity (0.30)", "Risk identification (0.25)", "Dependency mapping (0.25)", "Pattern alignment (0.20)"]
      thresholds:
        high_80_plus: { action: "Finalize plan.md and proceed to Step 7", cite: "Document key sources in plan.md" }
        medium_40_79: { action: "Proceed but flag uncertainties", requirement: "Add RISK markers" }
        low_below_40: { action: "STOP - Request research spike or clarification", wait_for: "User decision" }
      escalation: { trigger: "2 failed attempts OR 10 minutes", action: "Present options to user" }
    validation: approach_defined

  step_6_5_checkpoint_planning:
    purpose: Save context checkpoint after planning phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to planning milestone for session recovery
    - Preserve planning decisions, exploration findings, and technical approach
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - planning phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__planning_complete.md"
    validation: checkpoint_saved

  step_7_task_breakdown:
    purpose: Break plan into executable implementation tasks (Level 1+ requirement)
    level_requirement: "Level 1+ (Baseline - required at all levels)"
    activities:
    - Run check-prerequisites.sh --json to get FEATURE_DIR
    - Load plan.md for tech stack and architecture
    - Load spec.md for user stories and priorities
    - Load optional artifacts (research)
    - Extract user stories with priorities (P0, P1, P2, P3)
    - Generate tasks organized by user story
    - Create dependency graph for task ordering
    - Mark parallel-executable tasks with [P]
    - Define task phases (Setup, Tests, Core, Integration, Polish)
    - Generate time estimates (15-60 min per task)
    - Create tasks.md with proper structure
    - Validate task format and coverage
    outputs:
    - tasks.md: implementation_breakdown
    template: .opencode/skill/system-spec-kit/templates/level_2/tasks.md
    validation: tasks_documented

    phase_gate_checkpoint:
      trigger: "After Step 7 completes"
      action: |
        STOP and verify Phase Gate:
        1. spec.md exists → If not, return to Step 3
        2. plan.md exists → If not, return to Step 6
        3. tasks.md exists → If not, this step failed
        4. No [NEEDS CLARIFICATION] in spec.md
        5. Mark "PHASE GATE: PASSED"
        6. ONLY THEN proceed to Step 8
      enforcement: HARD_BLOCK

  step_8_analysis:
    purpose: Verify consistency across all artifacts
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs, analysis]
      complexity_boost: 10
      on_parallel_dispatch:
        agents:
        - { name: "consistency_analyzer", focus: "Cross-artifact consistency and requirement coverage" }
        - { name: "gap_detector", focus: "Missing requirements, underspecification, edge cases" }
      fallback: "Proceed with activities below"
    activities:
    - Load all artifacts (spec.md, plan.md, tasks.md)
    - Build requirements inventory from spec
    - Build task coverage mapping from tasks
    - Run detection passes for: Duplication, Ambiguity, Underspecification, Constitution alignment, Coverage, Inconsistency
    - Assign severity levels (CRITICAL, HIGH, MEDIUM, LOW)
    - Generate consistency report, coverage verification, gap analysis
    - Suggest remediations (non-destructive, user must approve)
    outputs: [consistency_report, coverage_verification, alignment_check, gap_analysis]
    validation: consistency_verified

  step_9_implementation_check:
    purpose: Verify all prerequisites for implementation
    activities:
    - Run check-prerequisites.sh --json --require-tasks
    - Verify plan.md and tasks.md exist
    - Check all checklists status
    - Verify no blockers exist
    - Verify environment is ready
    - Verify dependencies loaded
    - Generate implementation greenlight report
    checks: { prerequisites: verified, blockers: none, environment: ready }
    validation: prerequisites_verified

  step_9_5_preflight:
    name: "PREFLIGHT Capture"
    purpose: "Capture epistemic baseline before implementation"
    tool: "task_preflight"
    parameters: "specFolder, taskId, knowledgeScore, uncertaintyScore, contextScore"
    skip_conditions: ["Less than 10 LOC change", "User says skip preflight"]

  step_10_development:
    purpose: Execute implementation following task plan
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, testing]
      complexity_boost: 15
      on_parallel_dispatch:
        agents:
        - { name: "implementation_agent", focus: "Core implementation tasks from tasks.md" }
        - { name: "test_agent", focus: "Test implementation and validation" }
        warning: "Development tasks may have dependencies - verify task order"
      fallback: "Proceed with activities below"
    activities:
    - Load tasks.md and parse task structure
    - Execute implementation phase by phase
    - Setup first (project structure, dependencies, configuration)
    - Follow TDD approach (tests before code where applicable)
    - Core development (models, services, endpoints)
    - Integration work (database, middleware, logging)
    - Polish and validation (unit tests, optimization, docs)
    - Respect task dependencies (sequential vs parallel)
    - Update task checklist progressively (mark [X] when complete)
    - Validate against acceptance criteria
    - Log progress after each completed task
    - Document any deviations from plan
    approach: autonomous_implementation_with_checkpoints
    requirements:
    - follow: Check skills folder for coding standards
    - update: task_checklist_progressively
    - test: before_commit
    - validate: continuously
    confidence_checkpoint:
      evaluate_at: "Before each significant code change"
      per_task_assessment:
        scoring_factors: ["Implementation clarity (0.35)", "Pattern alignment (0.30)", "Risk awareness (0.35)"]
        thresholds:
          high_80_plus: { action: "Implement task, mark [x]" }
          medium_40_79: { action: "Implement with extra validation", requirement: "Add inline comments" }
          low_below_40: { action: "STOP - Do not implement uncertain code", wait_for: "Resolution" }
    debug_integration:
      failure_tracking: { enabled: true, counter_name: "task_failure_count", reset_on: "new_task", threshold: 3 }
      on_threshold_reached:
        if_auto_debug_flag:
          action: "auto_dispatch_debug"
        else:
          action: "suggest_debug"
          prompt: |
            Multiple fix attempts failed (3+) for task {current_task_id}
            A) Yes - Dispatch debug agent
            B) No - Continue debugging manually
            C) Skip task - Move to next task
            D) Pause - Stop workflow and review
      debug_dispatch:
        subagent_type: "general-purpose"
        timeout_ms: 120000
        context_includes: [error_message, affected_files, previous_attempts, current_task_id]
        on_complete: "show_checkpoint"

    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY: Read tasks.md → Count [ ] vs [x] → ALL must be [x] and code works → THEN mark complete
      failure_action: "Continue development - do not proceed to Step 11"
    validation: development_complete

  step_10_5_checkpoint_development:
    purpose: Save context checkpoint after development phase complete
    checkpoint: true
    memory_action: save
    activities:
    - Save context checkpoint using system-spec-kit skill
    - Record progress up to development milestone for session recovery
    - Preserve implementation decisions, code changes, and debugging insights
    tool_invocation:
      command: Read(".opencode/skill/system-spec-kit/SKILL.md")
      note: "Intermediate checkpoint - development phase complete"
    outputs:
    - checkpoint_file: "[SPEC_FOLDER]/memory/checkpoint__development_complete.md"
    validation: checkpoint_saved

  step_11_checklist_verify:
    purpose: Verify all P0/P1 checklist items are complete before claiming completion
    blocking: true
    level_requirement: "Level 2+"
    activities:
    - Load checklist.md from spec folder
    - Verify ALL P0 items are marked [x] with evidence
    - Verify ALL P1 items are either marked [x] or have documented user approval to defer
    - P2 items may be deferred without approval
    - Document verification results with evidence format
    evidence_format: "- [x] Task description [EVIDENCE: file.js:45-67 - implementation verified]"
    evidence_log_pattern: "[E:filename]"
    p0_enforcement:
      blocking: true
      on_incomplete: "P0 ITEMS INCOMPLETE - Cannot proceed. WORKFLOW HALTED."
    p1_enforcement:
      blocking: soft
      allow_deferral: true
      on_incomplete: "P1 items incomplete. A) Complete remaining B) Document deferral and proceed"
    outputs: [checklist_verification_report, evidence_documentation]
    validation: all_p0_complete

  step_12_completion:
    purpose: Generate implementation summary and verify completion
    activities:
    - Verify all tasks completed
    - Check implemented features match specification
    - Validate tests pass and coverage meets requirements
    - Confirm implementation follows technical plan
    - Generate implementation-summary.md
    - Update all task status to completed
    - Verify staging if environment provided
    summary_document:
      location: "[SPEC_FOLDER]/implementation-summary.md"
      required_sections: [files_modified_created, verification_steps_taken, deviations_from_plan, skill_updates, recommended_next_steps, browser_testing_results]
    verification_summary:
      checklist_verification:
        required: true
        must_include: [total_items_count, p0_status, p1_status, deferred_p2_items, checklist_link]
    validation: implementation_complete

    completion_checkpoint:
      enforcement: HARD_BLOCK
      before_marking_complete: |
        VERIFY: implementation-summary.md exists with all required sections → THEN mark complete
      required_file: "[SPEC_FOLDER]/implementation-summary.md"
      failure_action: "Create implementation-summary.md before proceeding"

  step_11_5_postflight:
    name: "POSTFLIGHT Capture"
    purpose: "Capture learning delta after implementation"
    tool: "task_postflight"
    parameters: "specFolder, taskId, knowledgeScore, uncertaintyScore, contextScore"
    skip_conditions: ["Less than 10 LOC change", "No PREFLIGHT was captured"]

  step_13_save_context:
    purpose: Save conversation context for documentation and team sharing
    activities:
    - Invoke system-spec-kit skill
    - Preserve session metadata and timeline
    - Preserve full dialogue flow with decisions
    - Auto-generate workflow flowcharts
    - Preserve file changes and implementation details
    - Index memory file for immediate search availability
    memory_creation:
      enforcement: HARD_BLOCK
      method: "MUST use generate-context.js script"
      command: "node .opencode/skill/system-spec-kit/scripts/dist/memory/generate-context.js [spec-folder-path]"
      forbidden: { tools: [Write, Edit], action: "NEVER manually create memory files", paths: ["*/memory/*.md", "specs/*/memory/*"] }
      violation_recovery: "DELETE manual file → run generate-context.js → verify ANCHORs → index via memory_save"
    tool_invocation:
      command: 'Read(".opencode/skill/system-spec-kit/SKILL.md")'
    outputs:
    - context_file: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md"
    validation: context_saved_successfully

    post_save_indexing:
      mcp_tool: memory_save
      invocation: 'spec_kit_memory_memory_save({ filePath: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md" })'
      critical_note: "Call semantic memory MCP DIRECTLY - NEVER through Code Mode"
      when: "Immediately after memory file is written to disk"

    anchor_requirements:
      enforcement: MANDATORY
      minimum_anchors: 2
      pattern: "[context-type]-[keywords]-[spec-number]"
      format: "<!-- ANCHOR:ID --> content <!-- /ANCHOR:ID -->"
      required_sections:
      - { context_type: "general", section: "Session summary", example_id: "GENERAL-SESSION-SUMMARY-{spec#}" }
      - { context_type: "decision", section: "Key decisions", example_id: "DECISION-{topic}-{spec#}" }
      optional_sections:
      - { context_type: "implementation", example_id: "IMPLEMENTATION-{feature}-{spec#}" }
      - { context_type: "files", example_id: "FILES-{spec#}" }
      benefit: "93% token savings on anchor-based retrieval"

    importance_tier:
      assign: important
      rationale: "Complete workflow represents significant implementation work"
      tier_reference: "constitutional > critical > important > normal > temporary > deprecated"

  step_14_handover_check:
    purpose: Offer session handover before workflow completion
    activities:
    - Check if user needs session continuity documentation
    - Offer to run /spec_kit:handover for comprehensive handover
    options:
    - { label: "Run Handover", action: "Execute handover workflow" }
    - { label: "Skip", action: "Proceed to termination" }
    note: "Handover is optional but recommended for complex implementations"
    validation: handover_offered

# ─────────────────────────────────────────────────────────────────
# WORKFLOW TERMINATION
# ─────────────────────────────────────────────────────────────────
termination:
  after_step: 14
  message: "SpecKit workflow completed successfully."

# ─────────────────────────────────────────────────────────────────
# CHECKPOINT PROTOCOL
# ─────────────────────────────────────────────────────────────────
checkpoint_protocol:
  display_format: "WORKFLOW CHECKPOINT - {checkpoint_title} | {checkpoint_content} | Progress: {progress_display}"
  autonomous_behavior: { pause_for_confirmation: true, default_action_on_timeout: "continue", timeout_seconds: 300 }

# ─────────────────────────────────────────────────────────────────
# QUALITY STANDARDS
# ─────────────────────────────────────────────────────────────────
quality_standards:
  documentation: [production_ready_examples, defensive_programming, error_handling, comprehensive_tests]
  code_examples: [working_snippets, error_handling, performance_optimized, accessible, browser_compatible]
  analysis_depth: [edge_cases, failure_modes, recovery_strategies, monitoring]

# ─────────────────────────────────────────────────────────────────
# AUTONOMOUS EXECUTION GUIDANCE
# ─────────────────────────────────────────────────────────────────
autonomous_execution:
  principle: "Execute workflow steps sequentially without user approval gates"
  decision_making: "Analyze thoroughly, make informed decisions, document reasoning, proceed with best judgment"
  validation_approach: "Self-validate at checkpoints, verify against quality standards, test continuously"
  uncertainty_handling: "Research before deciding, document assumptions, choose conservative approach"
  progress_tracking: "Update checklists, log milestones, document deviations, maintain audit trail"
  completion_criteria: "All steps completed, implementation validated, docs generated, quality met, context saved"

# ─────────────────────────────────────────────────────────────────
# ERROR RECOVERY
# ─────────────────────────────────────────────────────────────────
error_recovery:
  step_validation_fails: "Review requirements, ask clarifying questions, retry step"
  tests_fail: "Debug, fix, re-run before marking complete"
  prerequisites_insufficient: "Return to prior phase or ask user"
  environment_unavailable: "Skip browser testing, document limitation"
  unexpected_error: "Log error, document state, attempt graceful recovery"

# ─────────────────────────────────────────────────────────────────
# SUCCESS CRITERIA
# ─────────────────────────────────────────────────────────────────
success:
  specification: [requirements_defined, acceptance_criteria, approach_planned, dependencies_identified]
  implementation: [code_follows_standards, tests_pass, browser_validated, performance_acceptable]
  documentation: [spec_folder_complete, summary_created, deviations_documented, context_saved]
  quality: [checklist_validated, no_regressions, functionality_preserved, standards_maintained]

# ─────────────────────────────────────────────────────────────────
# RULES
# ─────────────────────────────────────────────────────────────────
rules:
  ALWAYS:
  - follow_workflow_sequence
  - document_all_changes
  - validate_before_completion
  - use_browser_for_staging_analysis
  - self_validate_and_proceed
  - do_not_prompt_for_user_approval
  - limit_context_to_active_scope
  - use_checklist_for_verification_level_2_plus
  - mark_checklist_items_with_evidence
  - complete_all_p0_items_before_done
  - get_user_approval_for_p1_deferrals
  NEVER:
  - skip_workflow_steps
  - ignore_blockers
  - submit_without_validation
  - over_engineer_or_expand_scope
  - break_existing_functionality
  - proceed_without_self_validation
  - invent_new_patterns_when_existing_work
  - claim_completion_without_checklist_verification_level_2_plus
  - skip_p0_checklist_items
  - defer_p1_items_without_user_approval
