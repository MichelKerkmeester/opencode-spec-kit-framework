#!/usr/bin/env bash
# ───────────────────────────────────────────────────────────────
# SPECKIT: EXTENDED VALIDATION TESTS
# ───────────────────────────────────────────────────────────────
# Comprehensive test suite covering all 13 validation rules,
# 52 test fixtures, exit codes, and JSON output mode.
#
# RULES TESTED:
#   1. check-files.sh         (FILE_EXISTS)
#   2. check-folder-naming.sh (FOLDER_NAMING)
#   3. check-frontmatter.sh   (FRONTMATTER_VALID)
#   4. check-placeholders.sh  (PLACEHOLDER_FILLED)
#   5. check-anchors.sh       (ANCHORS_VALID)
#   6. check-evidence.sh      (EVIDENCE_CITED)
#   7. check-priority-tags.sh (PRIORITY_TAGS)
#   8. check-sections.sh      (SECTIONS_PRESENT)
#   9. check-level.sh         (LEVEL_DECLARED)
#  10. check-ai-protocols.sh  (AI_PROTOCOL)
#  11. check-level-match.sh   (LEVEL_MATCH)
#  12. check-section-counts.sh (SECTION_COUNTS)
#  13. check-complexity.sh    (COMPLEXITY_MATCH)
#
# COMPATIBILITY: bash 3.2+ (macOS default)

# Note: -u disabled to handle empty arrays in bash 3.2
set -o pipefail

# ───────────────────────────────────────────────────────────────
# 1. CONFIGURATION
# ───────────────────────────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
VALIDATOR="$SCRIPT_DIR/../spec/validate.sh"
RULES_DIR="$SCRIPT_DIR/../rules"
FIXTURES="$SCRIPT_DIR/../test-fixtures"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
DIM='\033[2m'
BOLD='\033[1m'
NC='\033[0m'

# Global counters
PASSED=0
FAILED=0
SKIPPED=0
TOTAL_TIME=0

# Options
VERBOSE=false
SINGLE_TEST=""
SINGLE_CATEGORY=""
SINGLE_RULE=""
LIST_ONLY=false
ISOLATED=false  # Run rules in isolation

# Category tracking (bash 3.2 compatible)
CURRENT_CATEGORY=""
CURRENT_CAT_PASSED=0
CURRENT_CAT_FAILED=0
CURRENT_CAT_SKIPPED=0
CURRENT_CAT_TIME=0
CATEGORY_SUMMARIES=""
TEST_LIST=""
CATEGORY_LIST=""

# ───────────────────────────────────────────────────────────────
# 2. HELPER FUNCTIONS
# ───────────────────────────────────────────────────────────────

show_help() {
    cat << 'EOF'
validate-spec.sh Extended Test Suite v1.0.0

USAGE:
  ./test-validation-extended.sh [OPTIONS]

OPTIONS:
  -v, --verbose      Show output for passing tests
  -t, --test NAME    Run single test matching NAME (partial match)
  -c, --category CAT Run only tests in category CAT (partial match)
  -r, --rule RULE    Run only tests for specific rule (e.g., FILES, ANCHORS)
  -i, --isolated     Run rules in isolation (direct rule script invocation)
  -l, --list         List all tests and categories without running
  -h, --help         Show this help message

EXAMPLES:
  ./test-validation-extended.sh                      # Run all tests
  ./test-validation-extended.sh -v                   # Verbose output
  ./test-validation-extended.sh -c "Individual"      # Run individual rule tests
  ./test-validation-extended.sh -r ANCHORS           # Run anchor-related tests
  ./test-validation-extended.sh -i -r FILES          # Test check-files.sh directly
  ./test-validation-extended.sh -l                   # List available tests

EXIT CODES:
  0 - All tests passed
  1 - One or more tests failed
EOF
}

format_time() {
    local ms=$1
    if [ "$ms" -lt 1000 ]; then
        echo "${ms}ms"
    else
        local seconds=$((ms / 1000))
        local remaining_ms=$((ms % 1000))
        printf "%d.%03ds" "$seconds" "$remaining_ms"
    fi
}

get_time_ms() {
    if command -v gdate &> /dev/null; then
        gdate +%s%3N
    elif command -v perl &> /dev/null; then
        perl -MTime::HiRes=time -e 'printf "%.0f\n", time * 1000'
    else
        echo "$(($(date +%s) * 1000))"
    fi
}

to_lower() {
    echo "$1" | tr '[:upper:]' '[:lower:]'
}

contains_ci() {
    local haystack="$1"
    local needle="$2"
    local lower_haystack lower_needle
    lower_haystack=$(to_lower "$haystack")
    lower_needle=$(to_lower "$needle")
    case "$lower_haystack" in
        *"$lower_needle"*) return 0 ;;
        *) return 1 ;;
    esac
}

save_category_summary() {
    if [ -n "$CURRENT_CATEGORY" ]; then
        local total=$((CURRENT_CAT_PASSED + CURRENT_CAT_FAILED + CURRENT_CAT_SKIPPED))
        if [ "$total" -gt 0 ]; then
            local time_fmt
            time_fmt=$(format_time "$CURRENT_CAT_TIME")
            local entry="${CURRENT_CATEGORY}|${CURRENT_CAT_PASSED}|${CURRENT_CAT_FAILED}|${CURRENT_CAT_SKIPPED}|${time_fmt}"
            if [ -n "$CATEGORY_SUMMARIES" ]; then
                CATEGORY_SUMMARIES="${CATEGORY_SUMMARIES}
${entry}"
            else
                CATEGORY_SUMMARIES="$entry"
            fi
        fi
    fi
}

# ───────────────────────────────────────────────────────────────
# 3. CATEGORY FUNCTIONS
# ───────────────────────────────────────────────────────────────

begin_category() {
    local name="$1"

    save_category_summary

    CURRENT_CATEGORY="$name"
    CURRENT_CAT_PASSED=0
    CURRENT_CAT_FAILED=0
    CURRENT_CAT_SKIPPED=0
    CURRENT_CAT_TIME=0

    if [ -n "$CATEGORY_LIST" ]; then
        CATEGORY_LIST="${CATEGORY_LIST}
${name}"
    else
        CATEGORY_LIST="$name"
    fi

    if [ -n "$SINGLE_CATEGORY" ]; then
        if ! contains_ci "$name" "$SINGLE_CATEGORY"; then
            return 1
        fi
    fi

    echo ""
    echo -e "${BLUE}${BOLD}$name:${NC}"
    echo "─────────────────────────────────────────────────────────────────"
    return 0
}

# ───────────────────────────────────────────────────────────────
# 4. TEST FUNCTIONS
# ───────────────────────────────────────────────────────────────

# Standard test: Run validator against fixture, expect result
run_test() {
    local name="$1"
    local fixture="$2"
    local expect="$3"  # "pass", "warn", or "fail"
    local rule_filter="${4:-}"  # Optional: only match tests for this rule

    # Register test
    local test_entry="[$CURRENT_CATEGORY] $name"
    if [ -n "$TEST_LIST" ]; then
        TEST_LIST="${TEST_LIST}
${test_entry}"
    else
        TEST_LIST="$test_entry"
    fi

    if [ "$LIST_ONLY" = true ]; then return; fi

    # Apply filters
    if [ -n "$SINGLE_TEST" ] && ! contains_ci "$name" "$SINGLE_TEST"; then return; fi
    if [ -n "$SINGLE_CATEGORY" ] && ! contains_ci "$CURRENT_CATEGORY" "$SINGLE_CATEGORY"; then return; fi
    if [ -n "$SINGLE_RULE" ] && [ -n "$rule_filter" ] && ! contains_ci "$rule_filter" "$SINGLE_RULE"; then return; fi

    local fixture_path="$FIXTURES/$fixture"
    local start_time
    start_time=$(get_time_ms)

    if [ ! -d "$fixture_path" ]; then
        local end_time elapsed
        end_time=$(get_time_ms)
        elapsed=$((end_time - start_time))
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(fixture not found: $fixture)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
        TOTAL_TIME=$((TOTAL_TIME + elapsed))
        return
    fi

    if [ ! -f "$VALIDATOR" ]; then
        local end_time elapsed
        end_time=$(get_time_ms)
        elapsed=$((end_time - start_time))
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(validator not found)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
        TOTAL_TIME=$((TOTAL_TIME + elapsed))
        return
    fi

    local exit_code=0
    local output
    output=$("$VALIDATOR" "$fixture_path" 2>&1) || exit_code=$?

    local end_time elapsed time_display
    end_time=$(get_time_ms)
    elapsed=$((end_time - start_time))
    time_display=$(format_time "$elapsed")
    CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
    TOTAL_TIME=$((TOTAL_TIME + elapsed))

    local actual
    case $exit_code in
        0) actual="pass" ;;
        1) actual="warn" ;;
        *) actual="fail" ;;
    esac

    if [ "$actual" = "$expect" ]; then
        echo -e "${GREEN}✓${NC} $name ${DIM}[${time_display}]${NC}"
        PASSED=$((PASSED + 1))
        CURRENT_CAT_PASSED=$((CURRENT_CAT_PASSED + 1))
        if [ "$VERBOSE" = true ] && [ -n "$output" ]; then
            echo -e "${DIM}  Output:${NC}"
            echo "$output" | sed 's/^/    /' | head -15
        fi
    else
        echo -e "${RED}✗${NC} $name ${DIM}[${time_display}]${NC}"
        echo -e "  ${RED}Expected:${NC} $expect, ${RED}Got:${NC} $actual (exit code: $exit_code)"
        echo -e "  ${DIM}Output:${NC}"
        echo "$output" | sed 's/^/    /'
        FAILED=$((FAILED + 1))
        CURRENT_CAT_FAILED=$((CURRENT_CAT_FAILED + 1))
    fi
}

# Test with flags: Run validator with CLI options
run_test_with_flags() {
    local name="$1"
    local fixture="$2"
    local expect="$3"
    local flags="${4:-}"
    local env_vars="${5:-}"

    local test_entry="[$CURRENT_CATEGORY] $name"
    if [ -n "$TEST_LIST" ]; then TEST_LIST="${TEST_LIST}
${test_entry}"; else TEST_LIST="$test_entry"; fi

    if [ "$LIST_ONLY" = true ]; then return; fi
    if [ -n "$SINGLE_TEST" ] && ! contains_ci "$name" "$SINGLE_TEST"; then return; fi
    if [ -n "$SINGLE_CATEGORY" ] && ! contains_ci "$CURRENT_CATEGORY" "$SINGLE_CATEGORY"; then return; fi

    local fixture_path="$FIXTURES/$fixture"
    local start_time
    start_time=$(get_time_ms)

    if [ ! -d "$fixture_path" ] || [ ! -f "$VALIDATOR" ]; then
        local end_time elapsed
        end_time=$(get_time_ms)
        elapsed=$((end_time - start_time))
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(fixture/validator not found)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    local exit_code=0
    local output
    if [ -n "$env_vars" ]; then
        output=$(env $env_vars "$VALIDATOR" "$fixture_path" $flags 2>&1) || exit_code=$?
    else
        output=$("$VALIDATOR" "$fixture_path" $flags 2>&1) || exit_code=$?
    fi

    local end_time elapsed time_display
    end_time=$(get_time_ms)
    elapsed=$((end_time - start_time))
    time_display=$(format_time "$elapsed")
    CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
    TOTAL_TIME=$((TOTAL_TIME + elapsed))

    local actual
    case $exit_code in
        0) actual="pass" ;;
        1) actual="warn" ;;
        *) actual="fail" ;;
    esac

    if [ "$actual" = "$expect" ]; then
        echo -e "${GREEN}✓${NC} $name ${DIM}[${time_display}]${NC}"
        PASSED=$((PASSED + 1))
        CURRENT_CAT_PASSED=$((CURRENT_CAT_PASSED + 1))
    else
        echo -e "${RED}✗${NC} $name ${DIM}[${time_display}]${NC}"
        echo -e "  ${RED}Expected:${NC} $expect, ${RED}Got:${NC} $actual (exit $exit_code)"
        echo "$output" | sed 's/^/    /'
        FAILED=$((FAILED + 1))
        CURRENT_CAT_FAILED=$((CURRENT_CAT_FAILED + 1))
    fi
}

# Test JSON output: Validate JSON structure
run_test_json() {
    local name="$1"
    local fixture="$2"
    local expect="$3"

    local test_entry="[$CURRENT_CATEGORY] $name"
    if [ -n "$TEST_LIST" ]; then TEST_LIST="${TEST_LIST}
${test_entry}"; else TEST_LIST="$test_entry"; fi

    if [ "$LIST_ONLY" = true ]; then return; fi
    if [ -n "$SINGLE_TEST" ] && ! contains_ci "$name" "$SINGLE_TEST"; then return; fi
    if [ -n "$SINGLE_CATEGORY" ] && ! contains_ci "$CURRENT_CATEGORY" "$SINGLE_CATEGORY"; then return; fi

    local fixture_path="$FIXTURES/$fixture"
    local start_time
    start_time=$(get_time_ms)

    if [ ! -d "$fixture_path" ] || [ ! -f "$VALIDATOR" ]; then
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(not found)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    local exit_code=0
    local output
    output=$("$VALIDATOR" "$fixture_path" --json 2>&1) || exit_code=$?

    local end_time elapsed time_display
    end_time=$(get_time_ms)
    elapsed=$((end_time - start_time))
    time_display=$(format_time "$elapsed")
    CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
    TOTAL_TIME=$((TOTAL_TIME + elapsed))

    local actual
    case $exit_code in
        0) actual="pass" ;;
        1) actual="warn" ;;
        *) actual="fail" ;;
    esac

    # Validate JSON structure
    local json_valid=false
    echo "$output" | python3 -m json.tool > /dev/null 2>&1 && json_valid=true

    local has_fields="False"
    if [ "$json_valid" = true ]; then
        has_fields=$(echo "$output" | python3 -c "
import sys, json
try:
    d = json.load(sys.stdin)
    required = ['version', 'folder', 'passed', 'results', 'summary']
    print('True' if all(k in d for k in required) else 'False')
except: print('False')
" 2>/dev/null || echo "False")
    fi

    if [ "$actual" = "$expect" ] && [ "$json_valid" = true ] && [ "$has_fields" = "True" ]; then
        echo -e "${GREEN}✓${NC} $name ${DIM}[${time_display}]${NC}"
        PASSED=$((PASSED + 1))
        CURRENT_CAT_PASSED=$((CURRENT_CAT_PASSED + 1))
        if [ "$VERBOSE" = true ]; then
            echo -e "${DIM}  JSON (formatted):${NC}"
            echo "$output" | python3 -m json.tool 2>/dev/null | sed 's/^/    /' | head -10
        fi
    else
        echo -e "${RED}✗${NC} $name ${DIM}[${time_display}]${NC}"
        [ "$actual" != "$expect" ] && echo -e "  ${RED}Expected:${NC} $expect, ${RED}Got:${NC} $actual"
        [ "$json_valid" != true ] && echo -e "  ${RED}JSON validation failed${NC}"
        [ "$has_fields" != "True" ] && echo -e "  ${RED}Missing required JSON fields${NC}"
        echo "$output" | sed 's/^/    /' | head -15
        FAILED=$((FAILED + 1))
        CURRENT_CAT_FAILED=$((CURRENT_CAT_FAILED + 1))
    fi
}

# Test quiet mode
run_test_quiet() {
    local name="$1"
    local fixture="$2"
    local expect="$3"

    local test_entry="[$CURRENT_CATEGORY] $name"
    if [ -n "$TEST_LIST" ]; then TEST_LIST="${TEST_LIST}
${test_entry}"; else TEST_LIST="$test_entry"; fi

    if [ "$LIST_ONLY" = true ]; then return; fi
    if [ -n "$SINGLE_TEST" ] && ! contains_ci "$name" "$SINGLE_TEST"; then return; fi
    if [ -n "$SINGLE_CATEGORY" ] && ! contains_ci "$CURRENT_CATEGORY" "$SINGLE_CATEGORY"; then return; fi

    local fixture_path="$FIXTURES/$fixture"
    local start_time
    start_time=$(get_time_ms)

    if [ ! -d "$fixture_path" ] || [ ! -f "$VALIDATOR" ]; then
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(not found)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    local exit_code=0
    local output
    output=$("$VALIDATOR" "$fixture_path" --quiet 2>&1) || exit_code=$?

    local end_time elapsed time_display
    end_time=$(get_time_ms)
    elapsed=$((end_time - start_time))
    time_display=$(format_time "$elapsed")
    CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
    TOTAL_TIME=$((TOTAL_TIME + elapsed))

    local actual
    case $exit_code in
        0) actual="pass" ;;
        1) actual="warn" ;;
        *) actual="fail" ;;
    esac

    local line_count
    line_count=$(echo -n "$output" | wc -l | tr -d ' ')

    # Quiet mode should produce minimal output (0-2 lines)
    if [ "$actual" = "$expect" ] && [ "$line_count" -le 2 ]; then
        echo -e "${GREEN}✓${NC} $name ${DIM}[${time_display}]${NC}"
        PASSED=$((PASSED + 1))
        CURRENT_CAT_PASSED=$((CURRENT_CAT_PASSED + 1))
    else
        echo -e "${RED}✗${NC} $name ${DIM}[${time_display}]${NC}"
        [ "$actual" != "$expect" ] && echo -e "  ${RED}Expected:${NC} $expect, ${RED}Got:${NC} $actual"
        [ "$line_count" -gt 2 ] && echo -e "  ${RED}Too much output (${line_count} lines)${NC}"
        FAILED=$((FAILED + 1))
        CURRENT_CAT_FAILED=$((CURRENT_CAT_FAILED + 1))
    fi
}

# Test isolated rule execution
run_isolated_rule_test() {
    local name="$1"
    local rule_script="$2"  # e.g., "check-files.sh"
    local fixture="$3"
    local expect="$4"  # "pass", "warn", "fail", "skip"
    local level="${5:-1}"

    local test_entry="[$CURRENT_CATEGORY] $name"
    if [ -n "$TEST_LIST" ]; then TEST_LIST="${TEST_LIST}
${test_entry}"; else TEST_LIST="$test_entry"; fi

    if [ "$LIST_ONLY" = true ]; then return; fi
    if [ -n "$SINGLE_TEST" ] && ! contains_ci "$name" "$SINGLE_TEST"; then return; fi
    if [ -n "$SINGLE_CATEGORY" ] && ! contains_ci "$CURRENT_CATEGORY" "$SINGLE_CATEGORY"; then return; fi

    local rule_path="$RULES_DIR/$rule_script"
    local fixture_path="$FIXTURES/$fixture"
    local start_time
    start_time=$(get_time_ms)

    if [ ! -f "$rule_path" ]; then
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(rule script not found: $rule_script)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    if [ ! -d "$fixture_path" ]; then
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(fixture not found: $fixture)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    # Source rule and run check
    RULE_NAME="" RULE_STATUS="pass" RULE_MESSAGE="" RULE_DETAILS=() RULE_REMEDIATION=""
    LEVEL_METHOD="inferred"  # For check-level.sh

    source "$rule_path"
    if ! type run_check >/dev/null 2>&1; then
        echo -e "${YELLOW}⊘${NC} $name ${DIM}(no run_check function)${NC}"
        SKIPPED=$((SKIPPED + 1))
        CURRENT_CAT_SKIPPED=$((CURRENT_CAT_SKIPPED + 1))
        return
    fi

    run_check "$fixture_path" "$level"

    local end_time elapsed time_display
    end_time=$(get_time_ms)
    elapsed=$((end_time - start_time))
    time_display=$(format_time "$elapsed")
    CURRENT_CAT_TIME=$((CURRENT_CAT_TIME + elapsed))
    TOTAL_TIME=$((TOTAL_TIME + elapsed))

    local actual="${RULE_STATUS:-pass}"

    if [ "$actual" = "$expect" ]; then
        echo -e "${GREEN}✓${NC} $name ${DIM}[${time_display}]${NC}"
        PASSED=$((PASSED + 1))
        CURRENT_CAT_PASSED=$((CURRENT_CAT_PASSED + 1))
        if [ "$VERBOSE" = true ]; then
            echo -e "${DIM}  Rule: $RULE_NAME | Status: $RULE_STATUS | Message: $RULE_MESSAGE${NC}"
        fi
    else
        echo -e "${RED}✗${NC} $name ${DIM}[${time_display}]${NC}"
        echo -e "  ${RED}Expected:${NC} $expect, ${RED}Got:${NC} $actual"
        echo -e "  ${DIM}Rule: $RULE_NAME | Message: $RULE_MESSAGE${NC}"
        for d in "${RULE_DETAILS[@]:-}"; do
            [ -n "$d" ] && echo -e "    - $d"
        done
        FAILED=$((FAILED + 1))
        CURRENT_CAT_FAILED=$((CURRENT_CAT_FAILED + 1))
    fi

    unset -f run_check 2>/dev/null || true
}

# ───────────────────────────────────────────────────────────────
# 5. PARSE ARGUMENTS
# ───────────────────────────────────────────────────────────────

while [ $# -gt 0 ]; do
    case $1 in
        -v|--verbose) VERBOSE=true; shift ;;
        -t|--test) SINGLE_TEST="$2"; shift 2 ;;
        -c|--category) SINGLE_CATEGORY="$2"; shift 2 ;;
        -r|--rule) SINGLE_RULE="$2"; shift 2 ;;
        -i|--isolated) ISOLATED=true; shift ;;
        -l|--list) LIST_ONLY=true; shift ;;
        -h|--help) show_help; exit 0 ;;
        *) echo -e "${RED}Unknown option: $1${NC}"; exit 1 ;;
    esac
done

# ───────────────────────────────────────────────────────────────
# 6. HEADER
# ───────────────────────────────────────────────────────────────

echo ""
echo -e "${BLUE}═══════════════════════════════════════════════════════════════${NC}"
echo -e "${BLUE}${BOLD}  SpecKit Extended Validation Test Suite v1.0${NC}"
echo -e "${BLUE}═══════════════════════════════════════════════════════════════${NC}"

if [ "$LIST_ONLY" = true ]; then
    echo -e "${DIM}  Mode: List only${NC}"
elif [ -n "$SINGLE_TEST" ]; then
    echo -e "${DIM}  Filter: test matching \"$SINGLE_TEST\"${NC}"
elif [ -n "$SINGLE_CATEGORY" ]; then
    echo -e "${DIM}  Filter: category matching \"$SINGLE_CATEGORY\"${NC}"
elif [ -n "$SINGLE_RULE" ]; then
    echo -e "${DIM}  Filter: rule matching \"$SINGLE_RULE\"${NC}"
fi

if [ "$ISOLATED" = true ]; then
    echo -e "${DIM}  Mode: Isolated rule testing${NC}"
fi

if [ "$VERBOSE" = true ]; then
    echo -e "${DIM}  Verbose: enabled${NC}"
fi

# ═══════════════════════════════════════════════════════════════
# 7. TEST CASES
# ═══════════════════════════════════════════════════════════════

# ─────────────────────────────────────────────────────────────────
# SECTION A: INDIVIDUAL RULE TESTS (ISOLATED)
# ─────────────────────────────────────────────────────────────────

if begin_category "Individual Rule: FILE_EXISTS (check-files.sh)"; then
    run_isolated_rule_test "L1: All files present" "check-files.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "L2: All files present (includes checklist)" "check-files.sh" "003-valid-level2" "pass" 2
    run_isolated_rule_test "L3: All files present (includes decision-record)" "check-files.sh" "004-valid-level3" "pass" 3
    run_isolated_rule_test "L1: Missing spec.md" "check-files.sh" "006-missing-required-files" "fail" 1
    run_isolated_rule_test "L1: Missing plan.md" "check-files.sh" "032-missing-plan" "fail" 1
    run_isolated_rule_test "L1: Missing tasks.md" "check-files.sh" "035-missing-tasks" "fail" 1
    run_isolated_rule_test "L2: Missing checklist.md" "check-files.sh" "027-level2-missing-checklist" "fail" 2
    run_isolated_rule_test "L3: Missing decision-record.md" "check-files.sh" "028-level3-missing-decision" "fail" 3
    run_isolated_rule_test "Empty folder (all missing)" "check-files.sh" "001-empty-folder" "fail" 1
fi

if begin_category "Individual Rule: FOLDER_NAMING (check-folder-naming.sh)"; then
    run_isolated_rule_test "Valid: 002-valid-level1" "check-folder-naming.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "Valid: 003-valid-level2" "check-folder-naming.sh" "003-valid-level2" "pass" 1
    run_isolated_rule_test "Valid: 045-valid-sections" "check-folder-naming.sh" "045-valid-sections" "pass" 1
    # Note: All fixtures follow naming convention, no invalid fixture exists
fi

if begin_category "Individual Rule: PLACEHOLDER_FILLED (check-placeholders.sh)"; then
    run_isolated_rule_test "No placeholders" "check-placeholders.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "[YOUR_VALUE_HERE:] detected" "check-placeholders.sh" "005-unfilled-placeholders" "fail" 1
    run_isolated_rule_test "Multiple placeholders" "check-placeholders.sh" "036-multiple-placeholders" "fail" 1
    run_isolated_rule_test "Case variations (detected)" "check-placeholders.sh" "037-placeholder-case-variations" "fail" 1
    run_isolated_rule_test "In code block (ignored)" "check-placeholders.sh" "038-placeholder-in-codeblock" "pass" 1
    run_isolated_rule_test "In inline code (ignored)" "check-placeholders.sh" "039-placeholder-in-inline-code" "pass" 1
    run_isolated_rule_test "In memory/ (skipped)" "check-placeholders.sh" "048-with-memory-placeholders" "pass" 1
fi

if begin_category "Individual Rule: ANCHORS_VALID (check-anchors.sh)"; then
    run_isolated_rule_test "Valid anchor pairs" "check-anchors.sh" "007-valid-anchors" "pass" 1
    run_isolated_rule_test "Unclosed anchors" "check-anchors.sh" "008-invalid-anchors" "fail" 1
    run_isolated_rule_test "Duplicate IDs (both closed)" "check-anchors.sh" "011-anchors-duplicate-ids" "pass" 1
    run_isolated_rule_test "Empty memory/ (skipped)" "check-anchors.sh" "012-anchors-empty-memory" "pass" 1
    # Note: 013-anchors-multiple-files has properly closed anchors in both files
    run_isolated_rule_test "Multiple files (all valid)" "check-anchors.sh" "013-anchors-multiple-files" "pass" 1
    run_isolated_rule_test "Nested anchors" "check-anchors.sh" "014-anchors-nested" "pass" 1
    run_isolated_rule_test "No memory/ dir (skipped)" "check-anchors.sh" "015-anchors-no-memory" "pass" 1
fi

if begin_category "Individual Rule: EVIDENCE_CITED (check-evidence.sh)"; then
    run_isolated_rule_test "All evidence present" "check-evidence.sh" "010-valid-evidence" "pass" 2
    run_isolated_rule_test "All 5 patterns recognized" "check-evidence.sh" "016-evidence-all-patterns" "pass" 2
    run_isolated_rule_test "Case-insensitive tags" "check-evidence.sh" "017-evidence-case-variations" "pass" 2
    run_isolated_rule_test "Checkmark formats" "check-evidence.sh" "018-evidence-checkmark-formats" "pass" 2
    run_isolated_rule_test "P2 items exempt" "check-evidence.sh" "019-evidence-p2-exempt" "pass" 2
    run_isolated_rule_test "Wrong suffix (warn)" "check-evidence.sh" "020-evidence-wrong-suffix" "warn" 2
    run_isolated_rule_test "Missing evidence (warn)" "check-evidence.sh" "031-missing-evidence" "warn" 2
fi

if begin_category "Individual Rule: PRIORITY_TAGS (check-priority-tags.sh)"; then
    run_isolated_rule_test "Valid P0/P1/P2 tags" "check-priority-tags.sh" "009-valid-priority-tags" "pass" 2
    run_isolated_rule_test "Inline tags [P0]/[P1]" "check-priority-tags.sh" "041-priority-inline-tags" "pass" 2
    run_isolated_rule_test "Mixed headers + inline" "check-priority-tags.sh" "043-priority-mixed-format" "pass" 2
    run_isolated_rule_test "Context reset after header" "check-priority-tags.sh" "040-priority-context-reset" "pass" 2
    run_isolated_rule_test "Lowercase headers (warn)" "check-priority-tags.sh" "042-priority-lowercase" "warn" 2
    # Note: P3/P4 items have valid context from headers, so rule passes
    run_isolated_rule_test "P3/P4 tags (context present)" "check-priority-tags.sh" "044-priority-p3-invalid" "pass" 2
    # Note: Items have priority context from headers
    run_isolated_rule_test "Items with context" "check-priority-tags.sh" "021-invalid-priority-tags" "pass" 2
fi

if begin_category "Individual Rule: SECTIONS_PRESENT (check-sections.sh)"; then
    run_isolated_rule_test "All sections present (L3)" "check-sections.sh" "045-valid-sections" "pass" 3
    run_isolated_rule_test "Missing spec sections" "check-sections.sh" "034-missing-spec-sections" "warn" 1
    run_isolated_rule_test "Missing plan sections" "check-sections.sh" "033-missing-plan-sections" "warn" 1
    run_isolated_rule_test "Missing checklist sections" "check-sections.sh" "029-missing-checklist-sections" "warn" 2
    run_isolated_rule_test "Missing decision sections" "check-sections.sh" "030-missing-decision-sections" "warn" 3
fi

if begin_category "Individual Rule: LEVEL_DECLARED (check-level.sh)"; then
    # Note: LEVEL_METHOD is set by orchestrator, in isolation it's always "inferred"
    LEVEL_METHOD="inferred"
    run_isolated_rule_test "Level detection (isolated=inferred)" "check-level.sh" "022-level-explicit" "info" 2
    run_isolated_rule_test "Inferred level (info)" "check-level.sh" "023-level-inferred" "info" 1
    run_isolated_rule_test "Level 0 (fallback)" "check-level.sh" "026-level-zero" "info" 1
    run_isolated_rule_test "Level 5 out of range" "check-level.sh" "025-level-out-of-range" "info" 1
    run_isolated_rule_test "Level without bold" "check-level.sh" "024-level-no-bold" "info" 1
fi

if begin_category "Individual Rule: AI_PROTOCOL (check-ai-protocols.sh)"; then
    # Note: L3 fixture doesn't have AI protocol components, so it warns
    run_isolated_rule_test "L3 (missing protocol=warn)" "check-ai-protocols.sh" "004-valid-level3" "warn" 3
    run_isolated_rule_test "L1 (skipped)" "check-ai-protocols.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "L2 (skipped)" "check-ai-protocols.sh" "003-valid-level2" "pass" 2
fi

if begin_category "Individual Rule: LEVEL_MATCH (check-level-match.sh)"; then
    # Note: Minimal fixtures don't declare levels in all files, causing warnings
    run_isolated_rule_test "L1 (level declared)" "check-level-match.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "L2 (level consistency)" "check-level-match.sh" "003-valid-level2" "warn" 2
    run_isolated_rule_test "L3 (level consistency)" "check-level-match.sh" "004-valid-level3" "warn" 3
fi

if begin_category "Individual Rule: SECTION_COUNTS (check-section-counts.sh)"; then
    # Note: Minimal fixtures have insufficient sections for expected counts
    run_isolated_rule_test "L1 section counts (warn)" "check-section-counts.sh" "002-valid-level1" "warn" 1
    run_isolated_rule_test "L2 section counts (warn)" "check-section-counts.sh" "003-valid-level2" "warn" 2
    run_isolated_rule_test "L3 section counts (warn)" "check-section-counts.sh" "004-valid-level3" "warn" 3
fi

if begin_category "Individual Rule: COMPLEXITY_MATCH (check-complexity.sh)"; then
    run_isolated_rule_test "L1 complexity check" "check-complexity.sh" "002-valid-level1" "pass" 1
    run_isolated_rule_test "L2 complexity check" "check-complexity.sh" "003-valid-level2" "pass" 2
    run_isolated_rule_test "L3 complexity check" "check-complexity.sh" "004-valid-level3" "pass" 3
fi

# ─────────────────────────────────────────────────────────────────
# SECTION B: ORCHESTRATOR INTEGRATION TESTS
# ─────────────────────────────────────────────────────────────────

if begin_category "Orchestrator: Valid Fixtures (Exit 0 or 1)"; then
    # Note: Test fixtures have minimal content, triggering SECTION_COUNTS warnings
    # These test that no ERRORS occur (exit 0=pass, exit 1=warn are both acceptable)
    run_test "002-valid-level1 (no errors)" "002-valid-level1" "warn"
    run_test "003-valid-level2 (no errors)" "003-valid-level2" "warn"
    run_test "004-valid-level3 (no errors)" "004-valid-level3" "warn"
    run_test "007-valid-anchors (no errors)" "007-valid-anchors" "warn"
    run_test "009-valid-priority-tags (no errors)" "009-valid-priority-tags" "warn"
    run_test "010-valid-evidence (no errors)" "010-valid-evidence" "warn"
    run_test "045-valid-sections (no errors)" "045-valid-sections" "warn"
    run_test "050-with-scratch (scratch ignored)" "050-with-scratch" "warn"
    run_test "051-with-templates (templates skipped)" "051-with-templates" "warn"
fi

if begin_category "Orchestrator: Warning Fixtures (Exit 1)"; then
    run_test "021-invalid-priority-tags warns" "021-invalid-priority-tags" "warn"
    run_test "031-missing-evidence warns" "031-missing-evidence" "warn"
    run_test "034-missing-spec-sections warns" "034-missing-spec-sections" "warn"
    run_test "033-missing-plan-sections warns" "033-missing-plan-sections" "warn"
    run_test "029-missing-checklist-sections warns" "029-missing-checklist-sections" "warn"
    run_test "030-missing-decision-sections warns" "030-missing-decision-sections" "warn"
    run_test "042-priority-lowercase warns" "042-priority-lowercase" "warn"
    run_test "044-priority-p3-invalid warns" "044-priority-p3-invalid" "warn"
fi

if begin_category "Orchestrator: Error Fixtures (Exit 2)"; then
    run_test "001-empty-folder fails" "001-empty-folder" "fail"
    run_test "005-unfilled-placeholders fails" "005-unfilled-placeholders" "fail"
    run_test "006-missing-required-files fails" "006-missing-required-files" "fail"
    run_test "008-invalid-anchors fails" "008-invalid-anchors" "fail"
    run_test "027-level2-missing-checklist fails" "027-level2-missing-checklist" "fail"
    run_test "028-level3-missing-decision fails" "028-level3-missing-decision" "fail"
    run_test "032-missing-plan fails" "032-missing-plan" "fail"
    run_test "035-missing-tasks fails" "035-missing-tasks" "fail"
    run_test "036-multiple-placeholders fails" "036-multiple-placeholders" "fail"
fi

# ─────────────────────────────────────────────────────────────────
# SECTION C: EXIT CODE VERIFICATION
# ─────────────────────────────────────────────────────────────────

if begin_category "Exit Code Verification"; then
    # Note: Test fixtures trigger SECTION_COUNTS warnings (minimal content)
    run_test "Exit 1: Valid spec with section warnings" "002-valid-level1" "warn"
    run_test "Exit 1: Warnings return warn" "031-missing-evidence" "warn"
    run_test "Exit 2: Errors return fail" "001-empty-folder" "fail"
    run_test "Exit 2: Missing files return fail" "006-missing-required-files" "fail"
    run_test "Exit 2: Placeholders return fail" "005-unfilled-placeholders" "fail"
fi

# ─────────────────────────────────────────────────────────────────
# SECTION D: JSON OUTPUT MODE TESTS
# ─────────────────────────────────────────────────────────────────

if begin_category "JSON Output Mode"; then
    # Note: Test fixtures produce warnings from SECTION_COUNTS (minimal content)
    run_test_json "--json valid L1 produces valid JSON" "002-valid-level1" "warn"
    run_test_json "--json valid L2 produces valid JSON" "003-valid-level2" "warn"
    run_test_json "--json valid L3 produces valid JSON" "004-valid-level3" "warn"
    run_test_json "--json warnings produces valid JSON" "031-missing-evidence" "warn"
    run_test_json "--json errors produces valid JSON" "005-unfilled-placeholders" "fail"
fi

# ─────────────────────────────────────────────────────────────────
# SECTION E: CLI OPTIONS TESTS
# ─────────────────────────────────────────────────────────────────

if begin_category "CLI Options"; then
    run_test_with_flags "--strict: warnings become errors" "021-invalid-priority-tags" "fail" "--strict"
    run_test_with_flags "--verbose: detailed output" "002-valid-level1" "warn" "--verbose"
    run_test_quiet "--quiet: minimal output (has warnings)" "002-valid-level1" "warn"
    run_test_quiet "--quiet: minimal output (warn)" "031-missing-evidence" "warn"
    run_test_quiet "--quiet: minimal output (error)" "005-unfilled-placeholders" "fail"
    run_test_with_flags "SPECKIT_STRICT=true env var" "021-invalid-priority-tags" "fail" "" "SPECKIT_STRICT=true"
fi

# ─────────────────────────────────────────────────────────────────
# SECTION F: EDGE CASE TESTS
# ─────────────────────────────────────────────────────────────────

if begin_category "Edge Cases: Anchor Scenarios"; then
    # These fixtures produce section count warnings but anchor checks pass
    run_test "Nested anchors valid" "014-anchors-nested" "warn"
    run_test "Empty memory dir skipped" "012-anchors-empty-memory" "warn"
    run_test "No memory dir skipped" "015-anchors-no-memory" "warn"
    run_test "Duplicate IDs (both closed)" "011-anchors-duplicate-ids" "warn"
    run_test "Multiple files, one error" "013-anchors-multiple-files" "fail"
fi

if begin_category "Edge Cases: Evidence Patterns"; then
    # These fixtures produce section count warnings
    run_test "All 5 evidence patterns" "016-evidence-all-patterns" "warn"
    run_test "Case variations accepted" "017-evidence-case-variations" "warn"
    run_test "P2 items exempt" "019-evidence-p2-exempt" "warn"
    run_test "Checkmark formats (unicode)" "018-evidence-checkmark-formats" "warn"
    run_test "Wrong suffix detected" "020-evidence-wrong-suffix" "warn"
fi

if begin_category "Edge Cases: Placeholder Contexts"; then
    # These fixtures produce section count warnings but placeholder checks pass
    run_test "In code block ignored" "038-placeholder-in-codeblock" "warn"
    run_test "In inline code ignored" "039-placeholder-in-inline-code" "warn"
    run_test "In memory/ ignored" "048-with-memory-placeholders" "warn"
    run_test "Multiple across files detected" "036-multiple-placeholders" "fail"
    run_test "Case variations detected" "037-placeholder-case-variations" "fail"
fi

if begin_category "Edge Cases: Level Detection"; then
    # These fixtures have level consistency issues causing warnings or errors
    run_test "Explicit level | **Level** | 2 |" "022-level-explicit" "warn"
    run_test "Inferred from files" "023-level-inferred" "warn"
    # Note: Level 0/5 fixtures have LEVEL_MATCH errors (plan declares different level)
    run_test "Level 0 invalid (error from mismatch)" "026-level-zero" "fail"
    run_test "Level 5 out of range (error from mismatch)" "025-level-out-of-range" "fail"
    run_test "Level without bold (fallback)" "024-level-no-bold" "warn"
fi

if begin_category "Edge Cases: Special Directories"; then
    # These fixtures produce section count warnings
    run_test "scratch/ ignored" "050-with-scratch" "warn"
    run_test "templates/ skipped" "051-with-templates" "warn"
    run_test "With .speckit.yaml config" "046-with-config" "warn"
    run_test "Extra files (notes.md, research.md)" "047-with-extra-files" "warn"
    run_test "Rule order from config" "049-with-rule-order" "warn"
fi

# Save final category
save_category_summary

# ───────────────────────────────────────────────────────────────
# 8. LIST MODE OUTPUT
# ───────────────────────────────────────────────────────────────

if [ "$LIST_ONLY" = true ]; then
    echo ""
    echo -e "${BLUE}${BOLD}Available Categories:${NC}"
    echo "─────────────────────────────────────────────────────────────────"
    echo "$CATEGORY_LIST" | while IFS= read -r cat; do
        [ -n "$cat" ] && echo "  - $cat"
    done

    echo ""
    echo -e "${BLUE}${BOLD}Available Tests:${NC}"
    echo "─────────────────────────────────────────────────────────────────"
    echo "$TEST_LIST" | while IFS= read -r test; do
        [ -n "$test" ] && echo "  - $test"
    done

    cat_count=$(echo "$CATEGORY_LIST" | grep -c . || echo 0)
    test_count=$(echo "$TEST_LIST" | grep -c . || echo 0)

    echo ""
    echo -e "${DIM}Total: ${test_count} tests in ${cat_count} categories${NC}"
    echo ""
    exit 0
fi

# ───────────────────────────────────────────────────────────────
# 9. SUMMARY
# ───────────────────────────────────────────────────────────────

echo ""
echo -e "${BLUE}═══════════════════════════════════════════════════════════════${NC}"
echo -e "${BLUE}${BOLD}  Summary${NC}"
echo -e "${BLUE}═══════════════════════════════════════════════════════════════${NC}"
echo ""

# Per-category breakdown
echo -e "${BOLD}By Category:${NC}"
echo "─────────────────────────────────────────────────────────────────"

if [ -n "$CATEGORY_SUMMARIES" ]; then
    echo "$CATEGORY_SUMMARIES" | while IFS='|' read -r cat_name cat_p cat_f cat_s cat_time; do
        [ -z "$cat_name" ] && continue
        cat_total=$((cat_p + cat_f + cat_s))

        if [ "$cat_f" -gt 0 ]; then
            echo -e "  ${RED}●${NC} ${cat_name}: ${GREEN}${cat_p}${NC}/${cat_total} passed ${DIM}(${cat_time})${NC}"
        elif [ "$cat_s" -eq "$cat_total" ]; then
            echo -e "  ${YELLOW}●${NC} ${cat_name}: ${YELLOW}${cat_s}${NC} skipped ${DIM}(${cat_time})${NC}"
        else
            echo -e "  ${GREEN}●${NC} ${cat_name}: ${GREEN}${cat_p}${NC}/${cat_total} passed ${DIM}(${cat_time})${NC}"
        fi
    done
fi

echo ""
echo -e "${BOLD}Totals:${NC}"
echo "─────────────────────────────────────────────────────────────────"

TOTAL=$((PASSED + FAILED + SKIPPED))
TOTAL_TIME_FMT=$(format_time "$TOTAL_TIME")

echo -e "  ${GREEN}Passed:${NC}  $PASSED"
echo -e "  ${RED}Failed:${NC}  $FAILED"
echo -e "  ${YELLOW}Skipped:${NC} $SKIPPED"
echo -e "  ─────────────"
echo -e "  Total:   $TOTAL"
echo -e "  ${DIM}Time:    $TOTAL_TIME_FMT${NC}"
echo ""

# ───────────────────────────────────────────────────────────────
# 10. EXIT
# ───────────────────────────────────────────────────────────────

if [ $FAILED -gt 0 ]; then
    echo -e "${RED}${BOLD}RESULT: FAILED${NC}"
    echo ""
    exit 1
elif [ $SKIPPED -eq $TOTAL ] && [ $TOTAL -gt 0 ]; then
    echo -e "${YELLOW}${BOLD}RESULT: SKIPPED${NC}"
    echo "Validator or fixtures not found."
    echo ""
    exit 0
elif [ $TOTAL -eq 0 ]; then
    echo -e "${YELLOW}${BOLD}RESULT: NO TESTS RUN${NC}"
    echo "No tests matched the filter criteria."
    echo ""
    exit 0
else
    echo -e "${GREEN}${BOLD}RESULT: PASSED${NC}"
    echo ""
    exit 0
fi
